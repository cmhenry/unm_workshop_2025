{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f0e89250",
      "metadata": {
        "id": "f0e89250"
      },
      "source": [
        "# LLMs in Political Science Research via API\n",
        "\n",
        "Welcome to a tutorial notebook on the practical application of Large Language\n",
        "\n",
        "---\n",
        "\n",
        "Models (LLMs) in political science research. The integration of AI technologies into political analysis represents a fundamental shift in how researchers approach policy analysis, public opinion research, and institutional studies."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a25e61f",
      "metadata": {
        "id": "0a25e61f"
      },
      "source": [
        "### Core Applications\n",
        "\n",
        "Political science research now leverages LLMs for:\n",
        "\n",
        "- **Policy document analysis** - automated extraction of policy positions across legislative corpora\n",
        "- **Sentiment analysis** - measuring public opinion dynamics in social media and news coverage  \n",
        "- **Content classification** - categorizing political texts by ideology, topic, or rhetorical strategy\n",
        "- **Cross-national research** - enabling comparative analysis across multiple languages and contexts\n",
        "\n",
        "### Technical Implementation Overview\n",
        "\n",
        "This workshop provides hands-on experience with:\n",
        "\n",
        "1. **API fundamentals** - programmatic access to various LLM services\n",
        "2. **Structured data extraction** - entity recognition for political actors, organizations, and events\n",
        "3. **Scalable analysis workflows** - batch processing of large document collections\n",
        "4. **Methodological considerations** - addressing bias, validity, and reproducibility in computational approaches\n",
        "\n",
        "### Strategic Advantages\n",
        "\n",
        "API-based LLM integration enables:\n",
        "- **Reproducible research** through documented, version-controlled analysis pipelines\n",
        "- **Cost-effective scaling** for processing extensive legislative archives or media databases\n",
        "- **Customizable workflows** tailored to specific research questions\n",
        "- **Real-time analysis** of evolving political discourse and policy developments\n",
        "\n",
        "The following sessions will establish practical competency in leveraging these technologies for robust political science research.\n",
        "\n",
        "### What Makes This Approach Special\n",
        "\n",
        "Rather than relying on simple chat interfaces, you'll learn to harness the full power of LLMs through API access, enabling:\n",
        "- **Batch processing** of large document collections\n",
        "- **Customizable workflows** tailored to your specific research needs\n",
        "- **Reproducible research** methods with documented processes\n",
        "- **Integration** with existing computational social science tools and methodologies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3arv-b1RQ4yQ",
      "metadata": {
        "id": "3arv-b1RQ4yQ"
      },
      "source": [
        "## Section 1 - Introduction to LLMs and APIs\n",
        "\n",
        "In the first section, we will explore the basics of Large Language Models (LLMs) and how to interact with them using APIs. We will cover the following topics:\n",
        "- **What are LLMs?**: An introduction to Large Language Models, their capabilities, and how they can be applied in social science research.\n",
        "- **Setting Up Your Environment**: Instructions on how to set up your programming environment to interact with LLM APIs.\n",
        "- **Understanding APIs**: A brief overview of what APIs are, how they work, and why they are essential for accessing LLMs.\n",
        "- **OpenRouter API**: Introduction to the OpenRouter API, which provides access to various LLMs.\n",
        "- **Understanding JSON**: An introduction to JSON (JavaScript Object Notation), the data format commonly used for API responses, and how to work with it in Python."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e5b2d02",
      "metadata": {
        "id": "1e5b2d02"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7e87398b",
      "metadata": {
        "id": "7e87398b"
      },
      "source": [
        "## What are LLMs?\n",
        "\n",
        "**Large Language Models (LLMs)** are sophisticated artificial intelligence systems trained on vast collections of text data to understand, generate, and manipulate human language. Think of them as extremely well-read digital assistants that have absorbed millions of books, articles, websites, and documents, enabling them to engage with text in remarkably human-like ways.\n",
        "\n",
        "### How LLMs Work: The Basics\n",
        "\n",
        "LLMs use a technology called **transformer architecture** which wa introduced in landmark [2017 paper - Attention Is All You Need](https://arxiv.org/abs/1706.03762). This architecture allows them to:\n",
        "\n",
        "1. **Predict the next word** in a sequence based on context\n",
        "2. **Understand relationships** between words, sentences, and concepts\n",
        "3. **Generate coherent text** that follows patterns learned from training data\n",
        "\n",
        "Watch Javier de la Rosa explain LLMs in this video:\n",
        "https://youtu.be/VtkPhFwF-2Q?si=6CrZDx5jiN-fcoeZ&t=127\n",
        "\n",
        "### Key Terms\n",
        "\n",
        "#### **Training Data**\n",
        "The massive collection of texts used to teach the LLM. This typically includes:\n",
        "- Web content and reference materials\n",
        "- News articles and magazines\n",
        "- Academic papers and journals\n",
        "- Books and literature from various periods and cultures\n",
        "- **Important**: The quality and diversity of training data affects what the model \"knows\"\n",
        "\n",
        "#### **Tokens**\n",
        "The basic units of text that LLMs process. A token can be:\n",
        "- A whole word (\"democracy\")\n",
        "- Part of a word (\"demo\" + \"cratic\")\n",
        "- Punctuation marks\n",
        "- **Why it matters**: API costs are often calculated per token\n",
        "\n",
        "#### **Context Window**\n",
        "The amount of text an LLM can \"remember\" at once, measured in tokens. Common sizes:\n",
        "- **GPT-3.5**: ~4,000 tokens (‚âà3,000 words)\n",
        "- **GPT-4**: ~8,000-32,000 tokens\n",
        "- **Claude**: ~100,000+ tokens\n",
        "- **Gemini**: ~1,000,000 tokens\n",
        "- **Why it matters**: Determines how much text you can analyze at once\n",
        "\n",
        "#### **Prompt**\n",
        "The input text you give to an LLM to get a response. Effective prompting is crucial for good results.\n",
        "\n",
        "#### **Fine-tuning**\n",
        "The process of further training a model on specific data to improve performance for particular tasks.\n",
        "\n",
        "### Applications in Social Science\n",
        "\n",
        "#### **1. Text Analysis**\n",
        "- **Sentiment analysis** of historical documents\n",
        "- **Thematic analysis** across large corpora\n",
        "- **Stylometric analysis** for authorship attribution\n",
        "- **Content classification** and categorization\n",
        "\n",
        "#### **2. Language Processing**\n",
        "- **Translation** of texts\n",
        "- **Transcription** assistance for handwritten documents\n",
        "- **OCR error correction** in digitized materials\n",
        "\n",
        "#### **3. Research Assistance**\n",
        "- **Citation analysis** and bibliography generation\n",
        "- **Concept mapping** and knowledge extraction\n",
        "- **Hypothesis generation** from patterns in data\n",
        "\n",
        "#### **4. Content Generation**\n",
        "- **Metadata generation** for digital collections\n",
        "- **Summary creation** for large document sets\n",
        "- **Educational material** development\n",
        "\n",
        "### Limitations and Considerations\n",
        "\n",
        "#### **Accuracy Concerns**\n",
        "- LLMs can generate plausible but incorrect information (**hallucinations**)\n",
        "- Always verify important claims against primary sources\n",
        "- Use multiple models and cross-check results\n",
        "\n",
        "#### **Bias and Representation**\n",
        "- Training data reflects societal biases\n",
        "- May underrepresent certain cultures, languages, or perspectives\n",
        "- Critical evaluation is essential, especially for sensitive topics\n",
        "\n",
        "#### **Temporal Knowledge**\n",
        "- Models have knowledge cutoff dates\n",
        "- May not know about recent events or publications\n",
        "- Historical accuracy varies by period and region\n",
        "\n",
        "#### **Language Coverage**\n",
        "- Performance varies significantly across languages\n",
        "- Better results for well-represented languages (English, major European languages)\n",
        "- Limited effectiveness for minority or historical languages\n",
        "\n",
        "#### **Legal Considerations**\n",
        "- Legality of data acquisition for training models\n",
        "- Protection of user input; consider how your data is handled when using online AI applications\n",
        "\n",
        "### Popular LLM Models for Research\n",
        "\n",
        "#### **OpenAI's GPT Series**\n",
        "- **GPT-3.5**: Fast, cost-effective for many tasks\n",
        "- **GPT-4**: More capable, better reasoning, higher cost\n",
        "- **Strengths**: General knowledge, writing quality\n",
        "- **Best for**: Text generation, analysis, general research tasks\n",
        "\n",
        "#### **Anthropic's Claude**\n",
        "- **Claude-3**: Various sizes (Haiku, Sonnet, Opus)\n",
        "- **Strengths**: Large context windows, careful reasoning\n",
        "- **Best for**: Long document analysis, ethical considerations\n",
        "\n",
        "#### **Google's Gemini**\n",
        "- **Gemini Pro**: Competitive with GPT-4\n",
        "- **Strengths**: Multimodal capabilities, integration with Google services\n",
        "- **Best for**: Research integration, document processing\n",
        "\n",
        "#### **Open Source Models**\n",
        "- **Llama 2/3**: Meta's open-source models\n",
        "- **Mistral**: European open-source alternative\n",
        "- **Benefits**: Transparency, customization, data privacy, reproducibility\n",
        "\n",
        "### Getting Started: Questions to Ask\n",
        "\n",
        "Before using LLMs in your research, consider:\n",
        "\n",
        "1. **What specific task** do you want to accomplish?\n",
        "2. **How much text** will you be processing?\n",
        "3. **What level of accuracy** do you need?\n",
        "4. **Are there privacy concerns** with your data?\n",
        "5. **What's your budget** for API usage?\n",
        "6. **Do you need real-time results** or can processing take time?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cc4a007",
      "metadata": {
        "id": "7cc4a007"
      },
      "source": [
        "## LLM through UI versus LLM through API\n",
        "\n",
        "Using a **Large Language Model (LLM) through an API** means that instead of downloading or running the model on your own computer, you connect to a powerful AI system over the internet and *ask it to do tasks for you*‚Äîlike analyzing text, summarizing articles, extracting names and places, or generating new content.\n",
        "\n",
        "### Big Picture Overview\n",
        "\n",
        "Think of it like this:\n",
        "\n",
        "* **You** are the researcher with a question.\n",
        "* **The LLM** is a very smart assistant that understands and works with language.\n",
        "* **The API** is the bridge that lets you talk to this assistant in a structured, predictable way and get answers back in a structured, predictable way.\n",
        "\n",
        "You send your questions or text to the LLM through this bridge, and it sends back responses. This might involve tasks like:\n",
        "\n",
        "* Translating documents\n",
        "* Summarizing long texts\n",
        "* Identifying recurring themes in political speeches\n",
        "* Extracting dates, names, and places from archival material\n",
        "* Creating timelines or glossaries based on your sources\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Simple Client Server Arcitecture](https://raw.githubusercontent.com/ValRCS/BSSDH_2025_workshop_LLM_API/refs/heads/main/img/client_server.png)\n",
        "\n",
        "Generic client-server architecture - applicable to using LLMs as well\n",
        "[Src](https://medium.com/@tolanisilas3606/getting-started-with-llms-how-to-serve-llm-applications-as-api-endpoints-with-fastapi-in-python-af015399ef3e)"
      ],
      "metadata": {
        "id": "zWnW66j8asOj"
      },
      "id": "zWnW66j8asOj"
    },
    {
      "cell_type": "markdown",
      "id": "c5a338c5",
      "metadata": {
        "id": "c5a338c5"
      },
      "source": [
        "### Slightly Technical Overview: Using LLMs Through APIs\n",
        "\n",
        "Using **Large Language Models (LLMs)** through an **API (Application Programming Interface)** means that your computer communicates with a powerful language model over the internet using a common format and protocol‚Äîusually **HTTP requests** and **JSON data**.\n",
        "\n",
        "Here‚Äôs what that typically involves:\n",
        "\n",
        "* üîê **API Key**: You first obtain an API key‚Äîa kind of password that identifies you to the LLM service (e.g., OpenAI, Cohere, Google, Anthropic). This ensures secure access and tracks your usage.\n",
        "\n",
        "* üì¶ **JSON**: You send your input (like a text prompt or document) in a format called **JSON (JavaScript Object Notation)**, which is a simple way to structure data‚Äîkind of like filling out a digital form.\n",
        "\n",
        "* üåê **HTTP Request**: You send this JSON to the LLM using an **HTTP request**, which is the same basic method your browser uses to visit websites‚Äîbut in this case, it's your script or notebook making the request.\n",
        "\n",
        "* üß† **LLM Response**: The LLM processes your input and returns a **response** (also in JSON), containing the generated text, analysis, or extracted information.\n",
        "\n",
        "* üß™ **Python & Jupyter Notebooks**: Most Digital Humanities researchers use a **scripting interface** like **Python**, often working in **Jupyter Notebooks**. These notebooks let you write and run code step by step, making it easy to send queries to the API, process responses, and analyze results alongside your research notes.\n",
        "\n",
        "In summary, using LLMs through an API gives you **programmatic, on-demand access to AI**, using simple web requests, structured data formats like JSON, and scripting environments like Python notebooks‚Äîideal for batch processing or large-scale analysis in Digital Humanities projects.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4afbee1",
      "metadata": {
        "id": "f4afbee1"
      },
      "source": [
        "### Comparing LLM Usage: API vs. UI (e.g., ChatGPT)\n",
        "\n",
        "| **Feature / Aspect**            | **LLM via API**                                                                 | **LLM via UI (e.g., ChatGPT website)**                                  |\n",
        "|----------------------------------|----------------------------------------------------------------------------------|-------------------------------------------------------------------------|\n",
        "| **Interface**                   | Code-based (e.g., Python, Jupyter Notebooks)                                     | Web-based (graphical user interface)                                   |\n",
        "| **Ease of Use**                 | Requires some technical knowledge (coding, HTTP, JSON)                           | Very easy to use ‚Äî no coding required                                  |\n",
        "| **Customization**              | Highly customizable (prompts, formatting, logic, parameters)                     | Limited to what the UI allows                                          |\n",
        "| **System Prompt Control**      | You define your own system prompt (full control over model behavior)             | Often hidden or pre-set by provider ‚Äî not user-visible or editable     |\n",
        "| **Automation**                 | Supports batch processing, loops, and integration into workflows                 | Manual, one prompt at a time                                           |\n",
        "| **Scalability**                | Good for large-scale or repetitive tasks (e.g., thousands of documents)          | Not ideal for repetitive or high-volume tasks                          |\n",
        "| **Output Control**             | Easy to parse and post-process structured results (e.g., JSON, CSV)              | Output is plain text, harder to reuse automatically                    |\n",
        "| **Learning Curve**             | Higher ‚Äî needs understanding of programming, HTTP, JSON                          | Low ‚Äî intuitive for most users                                         |\n",
        "| **Cost Management**            | Detailed usage tracking, adjustable per-token budgets                            | Usage-based, but detailed per-task tracking may be limited             |\n",
        "| **Use in Research Pipelines**  | Can be integrated into DH workflows and pipelines                                | Mostly standalone usage                                                |\n",
        "| **Examples of Use**            | - Annotating texts in bulk  <br> - Named entity recognition  <br> - Concept tagging | - Asking one-off questions <br> - Drafting summaries or brainstorming  |\n",
        "| **Reproducibility**            | Easy to document, version, and rerun scripts                                     | Harder to reproduce exact interactions                                 |\n",
        "| **Collaboration & Sharing**    | Code and notebooks can be shared, versioned, and reused                          | Limited to screenshots or copy-pasting conversation                    |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dangerous instructions from UI\n",
        "\n",
        "With Chat based interface the LLM provider supplies some extra instructions which user does not see and it can lead to less than ideal results:\n",
        "\n",
        "April 2025 - [Update that made ChatGPT 'dangerously' sycophantic pulled](https://www.bbc.com/news/articles/cn4jnwdvg9qo)"
      ],
      "metadata": {
        "id": "xrre5fCEVtUW"
      },
      "id": "xrre5fCEVtUW"
    },
    {
      "cell_type": "markdown",
      "id": "e2c3de3b",
      "metadata": {
        "id": "e2c3de3b"
      },
      "source": [
        "## OpenRouter API\n",
        "\n",
        "[OpenRouter](https://openrouter.ai/) is a unified API provider that provides access to multiple LLM providers through a single interface. This makes it convenient to experiment with different models and compare their performance for humanities research tasks.\n",
        "\n",
        "### What is OpenRouter?\n",
        "\n",
        "**OpenRouter** acts as a gateway to dozens of different LLM providers, allowing you to:\n",
        "- **Access multiple models** through a single API interface\n",
        "- **Compare performance** across different LLMs for the same task\n",
        "- **Switch between models** without changing your code structure\n",
        "- **Manage costs** by choosing models based on budget and performance needs\n",
        "\n",
        "Note: OpenRouter is NOT related to OpenAI, both are companies/organizations providing AI services. OpenRouter does offer a way to access these OpenAI services.\n",
        "\n",
        "### Key Advantages for Digital Humanities Research\n",
        "\n",
        "#### **1. Model Diversity**\n",
        "- **OpenAI models**: GPT-3.5, GPT-4, GPT-4 Turbo\n",
        "- **Anthropic models**: Claude-3 Haiku, Sonnet, Opus\n",
        "- **Google models**: Gemini Pro, Gemini Flash\n",
        "- **Open source models**: Llama, Mistral, and many others\n",
        "- **Specialized models**: Fine-tuned for specific tasks\n",
        "\n",
        "#### **2. Cost Optimization**\n",
        "- **Transparent pricing**: See exact costs per model\n",
        "- **Choose by budget**: Use cheaper models for initial testing\n",
        "- **Scale appropriately**: Use powerful models only when needed\n",
        "- **Usage tracking**: Monitor your spending in real-time\n",
        "\n",
        "#### **3. Unified Interface**\n",
        "- **Consistent API**: Same request format for all models\n",
        "- **Easy switching**: Change models by modifying one parameter\n",
        "- **Standard responses**: Uniform JSON response structure\n",
        "- **Simplified authentication**: One API key for all providers\n",
        "\n",
        "### How to use after the workshop?\n",
        "\n",
        "Register for an OpenRouter account at [OpenRouter](https://openrouter.ai/). You should fund the account with a small amount of money to be able to request API keys and use the models.\n",
        "\n",
        "There are other aggregrators of LLMs, such as [Hugging Face](https://huggingface.co/) also providing other services, but OpenRouter is the most convenient for our purposes. It provides a unified interface to many models, including those from OpenAI, Anthropic(Claude), and Google(Gemini) and many others.\n",
        "\n",
        "You can use OpenRouter to sample different models (https://openrouter.ai/models) and compare their performance for your specific tasks. For truly large tasks, you could then use the model provider's own API directly, as OpenRouter is a wrapper around the original APIs. This way, you can take advantage of the best features of each model while maintaining a consistent interface.\n",
        "\n",
        "There are new models being release almost daily - over 400 to choose from as of mid 2025."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94b0f9e2",
      "metadata": {
        "id": "94b0f9e2"
      },
      "source": [
        "## Minimal example of LLM API usage\n",
        "\n",
        "Let's use OpenAI style API to interact with a model like GPT-3.5.\n",
        "\n",
        "Note: Similar example can be found at https://openrouter.ai/openai/gpt-3.5-turbo/api\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "486ebca9",
      "metadata": {
        "id": "486ebca9",
        "outputId": "8ddc44ee-7cb6-484f-ad7d-2014a51ddeb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your OpenRouter API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "The National Library of Latvia is located in Riga, the capital city of Latvia.\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "import getpass # we do not want to show the API key in the code ANYWHERE!!\n",
        "\n",
        "# we create a local variable to store the OpenRouter API key\n",
        "open_router_api_key = getpass.getpass(\"Enter your OpenRouter API key: \") # getpass will hide the input\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=open_router_api_key,\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"openai/gpt-3.5-turbo\",  # this can be changed by the user to any other model available on OpenRouter\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",  # this is the role of the user in the conversation - similar to how you would use it in a chat application\n",
        "      \"content\": \"Where is National Library of Latvia located?\" # this is so called user prompt, the query we ask the model\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to create a new query we do not need to get the key or client again as long as we have run the above cell in our current session\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"openai/gpt-3.5-turbo\",  # this can be changed by the user to any other model available on OpenRouter\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",  # this is the role of the user in the conversation - similar to how you would use it in a chat application\n",
        "      \"content\": \"What is BSSDH in Riga?\" # this is so called user prompt, the query we ask the model\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "T7D3EcMRcCGv"
      },
      "id": "T7D3EcMRcCGv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b57dc768",
      "metadata": {
        "id": "b57dc768"
      },
      "source": [
        "### Limitations of minimal example\n",
        "\n",
        "Above shows a working code but there are multiple limitations of this approach:\n",
        "\n",
        "* We always have to enter the API key manually\n",
        "* We have hardcoded the model name\n",
        "* We have hardcoded the user prompt\n",
        "* We have no system prompt - meaning we cannot control the behavior of the model\n",
        "* We have no other parameters for the model that might be useful\n",
        "* We are trusting OpenAI not to break the library with an update\n",
        "* We have no way to use the model in a batch mode\n",
        "* How would we save the results?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd2605c0",
      "metadata": {
        "id": "bd2605c0"
      },
      "source": [
        "## Setting Up Your Environment\n",
        "\n",
        "To interact with LLM APIs effectively, we need to set up our programming environment with the necessary libraries and configurations. This includes installing required packages and setting up API credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e0354b1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0354b1f",
        "outputId": "7579ce91-3601-49b2-911c-9d31f05ebb6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is an interactive notebook for this workshop on LLMs and APIs.\n",
            "Python version: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "Today's date and time: 2025-09-05 14:36:09.892017\n",
            "JSON module imported successfully.\n",
            "Path from pathlib imported successfully.\n",
            "Will import external libraries if available.\n",
            "Requests library version: 2.32.4\n",
            "TQDM library version: 4.67.1\n",
            "OpenAI library version: 1.104.2\n"
          ]
        }
      ],
      "source": [
        "# Let's print some basic information about this interactive notebook\n",
        "print(\"This is an interactive notebook for this workshop on LLMs and APIs.\")\n",
        "# first let's see what Python version we are using\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "# now today's date and time\n",
        "from datetime import datetime\n",
        "print(f\"Today's date and time: {datetime.now()}\")\n",
        "# we will need to work with JSON data, so let's import the json module\n",
        "import json\n",
        "print(\"JSON module imported successfully.\")\n",
        "# we will need to read and write files so let's import pathlib\n",
        "from pathlib import Path\n",
        "print(\"Path from pathlib imported successfully.\")\n",
        "# TODO for those with some experience it can be useful to print more information about the environment, free memory, drives, etc.\n",
        "print(\"Will import external libraries if available.\")\n",
        "# Let's also check if we have the requests library installed, which is commonly used for making API calls\n",
        "try:\n",
        "    import requests\n",
        "    print(f\"Requests library version: {requests.__version__}\")\n",
        "except ImportError:\n",
        "    print(\"Requests library is not installed. You can install it using 'pip install requests'.\")\n",
        "\n",
        "# above were standard libraries part of any Python distribution\n",
        "# below libraries are external libraries that are not part of the standard library\n",
        "# however, they come preinstalled in Google Colab so *should* be available in the Colab environment\n",
        "# if you are running this notebook locally, you may need to install them using pip\n",
        "\n",
        "# let's install tqdm for progress bars if not already installed\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "    # import version\n",
        "    from tqdm import __version__ as tqdm_version\n",
        "    print(f\"TQDM library version: {tqdm_version}\")\n",
        "except ImportError:\n",
        "    print(\"TQDM library is not installed. You can install it using 'pip install tqdm'.\")\n",
        "\n",
        "# now let's try importing OpenAI's library if available\n",
        "try:\n",
        "    import openai # we actually already imported a class from this library above but let's import the whole library\n",
        "    print(f\"OpenAI library version: {openai.__version__}\")\n",
        "except ImportError:\n",
        "    print(\"OpenAI library is not installed. You can install it using 'pip install openai'.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dad0ead",
      "metadata": {
        "id": "6dad0ead"
      },
      "source": [
        "### Why Check System Information and Library Versions?\n",
        "\n",
        "**Environment Documentation** is crucial for reproducible research and troubleshooting. Here's why we print this information:\n",
        "\n",
        "#### **1. Reproducibility**\n",
        "- **Version consistency**: Different library versions can produce different results\n",
        "- **Environment documentation**: Future researchers (including yourself) can recreate the exact same setup\n",
        "- **Research integrity**: Ensures your findings can be validated by others\n",
        "\n",
        "#### **2. Troubleshooting**\n",
        "- **Debugging assistance**: When code doesn't work, version information helps identify compatibility issues\n",
        "- **Support requests**: Technical support often requires knowing your exact environment setup\n",
        "- **Error diagnosis**: Many errors are version-specific and can be quickly resolved with this information\n",
        "\n",
        "#### **3. Best Practices**\n",
        "- **Methodological transparency**: Document all tools and versions used in your research\n",
        "- **Collaboration**: Team members can ensure they're using compatible environments\n",
        "- **Publication standards**: Many journals now require detailed technical specifications\n",
        "\n",
        "#### **4. API Compatibility**\n",
        "- **Service requirements**: Different LLM APIs may require specific library versions\n",
        "- **Feature availability**: Newer features might only be available in recent library versions\n",
        "- **Security updates**: Ensures you're using libraries with the latest security patches\n",
        "\n",
        "**üí° Pro Tip**: Always run this environment check at the beginning of your research sessions to catch any changes that might affect your results!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2be804e",
      "metadata": {
        "id": "a2be804e"
      },
      "source": [
        "## Understanding APIs\n",
        "\n",
        "**API (Application Programming Interface)** is a set of rules and protocols that allows different software applications to communicate with each other. Think of an API as a digital messenger that takes your request, tells a system what you want, and then brings the response back to you in a structured format.\n",
        "\n",
        "### The Restaurant Analogy\n",
        "\n",
        "Imagine you're at a restaurant:\n",
        "- **You** (the client) want to order food\n",
        "- **The kitchen** (the server) prepares the food\n",
        "- **The waiter** (the API) takes your order to the kitchen and brings your food back\n",
        "\n",
        "In the digital world:\n",
        "- **Your Python script** (the client) wants data or a service\n",
        "- **The LLM service** (the server) processes your request\n",
        "- **The API** takes your request and returns the results\n",
        "\n",
        "### Key API Concepts\n",
        "\n",
        "#### **HTTP Methods**\n",
        "APIs use standard web protocols:\n",
        "- **GET**: Retrieve information (like downloading a file)\n",
        "- **POST**: Send data for processing (like submitting a form)\n",
        "- **PUT**: Update existing data\n",
        "- **DELETE**: Remove data\n",
        "\n",
        "For LLM APIs, we primarily use **POST** to send text for analysis.\n",
        "\n",
        "#### **Request and Response**\n",
        "Every API interaction involves:\n",
        "1. **Request**: What you send to the API\n",
        "   - URL (endpoint)\n",
        "   - Headers (metadata like authorization)\n",
        "   - Body (your actual data/text)\n",
        "2. **Response**: What the API sends back\n",
        "   - Status code (200 = success, 404 = not found, etc.)\n",
        "   - Data (usually in JSON format)\n",
        "\n",
        "#### **Authentication**\n",
        "Most APIs require proof of identity:\n",
        "- **API Keys**: Secret strings that identify you\n",
        "- **Tokens**: Temporary credentials with specific permissions\n",
        "- **Rate Limits**: Restrictions on how many requests you can make\n",
        "\n",
        "### API Anatomy for LLM Services\n",
        "\n",
        "#### **Base URL**\n",
        "The main address of the API service:\n",
        "```\n",
        "https://openrouter.ai/api/v1/\n",
        "```\n",
        "\n",
        "#### **Endpoints**\n",
        "Specific functions within the API:\n",
        "```\n",
        "/chat/completions  # For sending messages to LLMs\n",
        "/models           # List available models\n",
        "/usage            # Check your usage statistics\n",
        "```\n",
        "\n",
        "#### **Complete URL**\n",
        "```\n",
        "https://openrouter.ai/api/v1/chat/completions\n",
        "```\n",
        "\n",
        "### Headers: The API's Metadata\n",
        "\n",
        "Headers provide essential information about your request:\n",
        "\n",
        "```python\n",
        "headers = {\n",
        "    \"Authorization\": \"Bearer YOUR_API_KEY\",\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"HTTP-Referer\": \"https://your-research-project.edu\",\n",
        "    \"X-Title\": \"Text Analysis\"\n",
        "}\n",
        "```\n",
        "\n",
        "#### **Common Headers Explained**\n",
        "- **Authorization**: Proves you're allowed to use the service\n",
        "- **Content-Type**: Tells the API what format your data is in\n",
        "- **HTTP-Referer**: (Optional) Identifies your project for tracking\n",
        "- **X-Title**: (Optional) Describes your application\n",
        "\n",
        "### Request Body: Your Actual Data\n",
        "\n",
        "The request body contains your instructions and text:\n",
        "\n",
        "```python\n",
        "request_body = {\n",
        "    \"model\": \"openai/gpt-3.5-turbo\",\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Analyze the sentiment of this historical document: [your text here]\"\n",
        "        }\n",
        "    ],\n",
        "    \"max_tokens\": 1000,\n",
        "    \"temperature\": 0.1\n",
        "}\n",
        "```\n",
        "\n",
        "#### **Key Parameters**\n",
        "- **model**: Which LLM to use\n",
        "- **messages**: Your conversation with the AI\n",
        "- **max_tokens**: Maximum length of response\n",
        "- **temperature**: Creativity level (0 = deterministic, 1 = creative)\n",
        "\n",
        "### Common API Response Formats\n",
        "\n",
        "#### **Successful Response (Status 200)**\n",
        "```json\n",
        "{\n",
        "  \"id\": \"chatcmpl-123\",\n",
        "  \"object\": \"chat.completion\",\n",
        "  \"created\": 1677652288,\n",
        "  \"model\": \"openai/gpt-3.5-turbo\",\n",
        "  \"usage\": {\n",
        "    \"prompt_tokens\": 56,\n",
        "    \"completion_tokens\": 31,\n",
        "    \"total_tokens\": 87\n",
        "  },\n",
        "  \"choices\": [\n",
        "    {\n",
        "      \"message\": {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"This historical document expresses predominantly negative sentiment regarding the economic policies...\"\n",
        "      },\n",
        "      \"finish_reason\": \"stop\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "#### **Error Response (Status 400+)**\n",
        "```json\n",
        "{\n",
        "  \"error\": {\n",
        "    \"message\": \"You exceeded your rate limit\",\n",
        "    \"type\": \"rate_limit_exceeded\",\n",
        "    \"code\": \"rate_limit_exceeded\"\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "### Political Science Use Cases\n",
        "\n",
        "#### **1. Political Speech Analysis**\n",
        "```python\n",
        "# Analyze political speech rhetoric\n",
        "request = {\n",
        "    \"model\": \"openai/gpt-4\",\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": \"Identify the rhetorical frames used for immigration in this political speech: [manuscript text]\"}\n",
        "    ]\n",
        "}\n",
        "```\n",
        "\n",
        "#### **2. Event Processing**\n",
        "```python\n",
        "# Extract entities from poilitical events\n",
        "request = {\n",
        "    \"model\": \"anthropic/claude-3-sonnet\",\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": \"Extract all person names, places, and dates from this news story on a battle event: [letter text]\"}\n",
        "    ]\n",
        "}\n",
        "```\n",
        "\n",
        "#### **3. Texts Comparison**\n",
        "```python\n",
        "# Compare texts\n",
        "request = {\n",
        "    \"model\": \"meta-llama/llama-2-70b-chat\",\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": \"Compare the themes used in these two political ads: [ad 1] vs [ad 2]\"}\n",
        "    ]\n",
        "}\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4a8ba359",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a8ba359",
        "outputId": "bb2f3ddb-889e-4e46-e037-eac2de7ecb81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenRouter API key loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# let's prompt user for OpenRouter API key\n",
        "import getpass\n",
        "\n",
        "# if open_router_api_key variable does not exist or is empty, we will prompt the user for it\n",
        "if 'open_router_api_key' not in locals() or not open_router_api_key:\n",
        "    open_router_api_key = getpass.getpass(\"Please enter your OpenRouter API key: \")\n",
        "    # save it to .env file for future use\n",
        "    # note Google Colab will destroy .env file after session ends, so you will need to enter it again next time\n",
        "    # this can be useful if you re-run the notebook and want to avoid entering the key again\n",
        "    print(\"Saving Open Router API key to .env file...\")\n",
        "    with open('.env', 'a') as f:\n",
        "        f.write(f'OPENROUTER_API_KEY={open_router_api_key}\\n')\n",
        "    print(\"Open Router API key saved to .env file.\")\n",
        "\n",
        "# we now should have the OpenRouter API key available\n",
        "if open_router_api_key:\n",
        "    print(\"OpenRouter API key loaded successfully.\")\n",
        "else:\n",
        "    print(\"OpenRouter API key not found. Please make sure you have it set in your environment variables or .env file.\")\n",
        "    print(\"You can also enter it manually when prompted during API calls.\")\n",
        "\n",
        "# key point we do not print it publicly it is stored as a variable under the name open_router_api_key - of course you can change the name to something more descriptive\n",
        "# but do not print it to the console or logs, as it is sensitive information"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf9a411e",
      "metadata": {
        "id": "cf9a411e"
      },
      "source": [
        "### After loading the API key\n",
        "\n",
        "\n",
        "\n",
        "Now that we have loaded the API key, let's learn a little bit about JSON and how to work with it in Python, as it is the format we will be using to communicate with the API."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "794ceaeb",
      "metadata": {
        "id": "794ceaeb",
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "## Understanding JSON\n",
        "\n",
        "JSON (JavaScript Object Notation) is a lightweight data format commonly used for API responses. It's human-readable and easy to work with in Python, making it ideal for handling structured data from LLM APIs.\n",
        "\n",
        "Official JSON website: [json.org](https://www.json.org/)\n",
        "\n",
        "\n",
        "### JSON Syntax: Complete Guide\n",
        "\n",
        "#### **Basic Structure Rules**\n",
        "1. **Data is in name/value pairs**\n",
        "2. **Data is separated by commas**\n",
        "3. **Curly braces hold objects**\n",
        "4. **Square brackets hold arrays**\n",
        "5. **Strings must use double quotes**\n",
        "\n",
        "#### **Data Types**\n",
        "\n",
        "##### **1. Strings**\n",
        "- Must be enclosed in **double quotes** (not single quotes)\n",
        "- Can contain Unicode characters\n",
        "- Escape sequences supported\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"simple_string\": \"Hello World\",\n",
        "  \"unicode_string\": \"Latvian flag! üá±üáª\",\n",
        "  \"escaped_string\": \"Quote: \\\"Hello\\\" and newline: \\n\",\n",
        "  \"empty_string\": \"\"\n",
        "}\n",
        "```\n",
        "\n",
        "##### **2. Numbers**\n",
        "- Integer or floating point\n",
        "- No leading zeros (except for decimal numbers)\n",
        "- Scientific notation supported\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"integer\": 42,\n",
        "  \"negative\": -17,\n",
        "  \"float\": 3.14159,\n",
        "  \"scientific\": 1.23e-10,\n",
        "  \"zero\": 0\n",
        "}\n",
        "```\n",
        "\n",
        "##### **3. Booleans**\n",
        "- Only `true` or `false` (lowercase)\n",
        "- No other boolean representations\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"is_published\": true,\n",
        "  \"is_draft\": false\n",
        "}\n",
        "```\n",
        "\n",
        "##### **4. Null**\n",
        "- Represents empty value\n",
        "- Written as `null` (lowercase)\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"optional_field\": null,\n",
        "  \"missing_data\": null\n",
        "}\n",
        "```\n",
        "\n",
        "##### **5. Objects**\n",
        "- Collections of key/value pairs\n",
        "- Keys must be strings in double quotes\n",
        "- Values can be any JSON data type\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"researcher\": {\n",
        "    \"name\": \"Dr. Colin Henry\",\n",
        "    \"institution\": \"University of Zurich\",\n",
        "    \"specialization\": \"Sitting at the Computer\",\n",
        "    \"contact\": {\n",
        "      \"email\": \"colin.henry@ipz.uzh.ch\",\n",
        "      \"phone\": null\n",
        "    }\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "##### **6. Arrays**\n",
        "- Ordered lists of values\n",
        "- Values can be any JSON data type (mixed types allowed)\n",
        "- Zero-indexed\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"research_topics\": [\n",
        "    \"Text Analysis\",\n",
        "    \"Data Visualization\",\n",
        "    \"Machine Learning\"\n",
        "  ],\n",
        "  \"mixed_array\": [\n",
        "    \"string\",\n",
        "    42,\n",
        "    true,\n",
        "    null,\n",
        "    {\"nested\": \"object\"},\n",
        "    [1, 2, 3]\n",
        "  ],\n",
        "  \"empty_array\": []\n",
        "}\n",
        "```\n",
        "\n",
        "#### **Nesting and Complex Structures**\n",
        "\n",
        "JSON supports unlimited nesting of objects and arrays:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"computational_social_science_project\": {\n",
        "    \"title\": \"Extremist Rhetoric Analysis\",\n",
        "    \"metadata\": {\n",
        "      \"created\": \"2025-01-15\",\n",
        "      \"version\": \"1.2\",\n",
        "      \"authors\": [\n",
        "        {\n",
        "          \"name\": \"Colin Henry\",\n",
        "          \"role\": \"Lead Developer\",\n",
        "          \"skills\": [\"Python\", \"Machine Learning\", \"APIs\"]\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    \"datasets\": [\n",
        "      {\n",
        "        \"name\": \"Extremist Texts\",\n",
        "        \"size\": 1200,\n",
        "        \"languages\": [\"English\", \"German\"],\n",
        "        \"analysis_results\": {\n",
        "          \"sentiment_scores\": [0.65, 0.72, 0.58],\n",
        "          \"themes\": {\n",
        "            \"exile\": 0.34,\n",
        "            \"identity\": 0.78,\n",
        "            \"nationalism\": 0.45\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "#### **LLM API Request Example**\n",
        "```json\n",
        "{\n",
        "  \"model\": \"openai/gpt-4\",\n",
        "  \"messages\": [\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You are a political science expert specializing in political extremism.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Analyze the following post for themes of political violence and identity: [text content here]\"\n",
        "    }\n",
        "  ],\n",
        "  \"max_tokens\": 1000,\n",
        "  \"temperature\": 0.1,\n",
        "  \"metadata\": {\n",
        "    \"research_project\": \"Extremist Rhetoric\",\n",
        "    \"researcher\": \"UNM Workshop Participant\",\n",
        "    \"date\": \"2025-09-03\"\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "### Common JSON Errors and How to Avoid Them\n",
        "\n",
        "#### **1. Syntax Errors**\n",
        "```json\n",
        "// ‚ùå WRONG - Single quotes\n",
        "{ 'author': 'Jane Smith' }\n",
        "\n",
        "// ‚úÖ CORRECT - Double quotes\n",
        "{ \"author\": \"Jane Smith\" }\n",
        "\n",
        "// ‚ùå WRONG - Trailing comma\n",
        "{\n",
        "  \"title\": \"Book\",\n",
        "  \"year\": 2024,\n",
        "}\n",
        "\n",
        "// ‚úÖ CORRECT - No trailing comma\n",
        "{\n",
        "  \"title\": \"Book\",\n",
        "  \"year\": 2024\n",
        "}\n",
        "\n",
        "// ‚ùå WRONG - Comments (not allowed in strict JSON)\n",
        "{\n",
        "  \"title\": \"Book\", // This is a comment\n",
        "  \"year\": 2024\n",
        "}\n",
        "\n",
        "// ‚úÖ CORRECT - No comments\n",
        "{\n",
        "  \"title\": \"Book\",\n",
        "  \"year\": 2024\n",
        "}\n",
        "```\n",
        "\n",
        "#### **2. Data Type Errors**\n",
        "```json\n",
        "// ‚ùå WRONG - Undefined values\n",
        "{\n",
        "  \"value\": undefined\n",
        "}\n",
        "\n",
        "// ‚úÖ CORRECT - Use null for missing values\n",
        "{\n",
        "  \"value\": null\n",
        "}\n",
        "\n",
        "// ‚ùå WRONG - Functions (not valid JSON)\n",
        "{\n",
        "  \"calculate\": function() { return 42; }\n",
        "}\n",
        "\n",
        "// ‚úÖ CORRECT - Only data, no functions\n",
        "{\n",
        "  \"result\": 42\n",
        "}\n",
        "```\n",
        "\n",
        "### Working with JSON in Python\n",
        "\n",
        "#### **Basic Operations**\n",
        "```python\n",
        "import json\n",
        "\n",
        "# Creating JSON from Python data\n",
        "data = {\n",
        "    \"title\": \"Research\",\n",
        "    \"authors\": [\"Henry\", \"Colin\"],\n",
        "    \"published\": True,\n",
        "    \"year\": 2025\n",
        "}\n",
        "\n",
        "# Convert to JSON string\n",
        "json_string = json.dumps(data)\n",
        "print(json_string)\n",
        "\n",
        "# Convert back to Python object\n",
        "parsed_data = json.loads(json_string)\n",
        "print(parsed_data[\"title\"])\n",
        "```\n",
        "\n",
        "#### **Pretty Printing**\n",
        "```python\n",
        "# Format JSON nicely\n",
        "pretty_json = json.dumps(data, indent=2, ensure_ascii=False)\n",
        "print(pretty_json)\n",
        "```\n",
        "\n",
        "#### **Reading/Writing JSON Files**\n",
        "```python\n",
        "# Write to file\n",
        "with open('research_data.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "# Read from file\n",
        "with open('research_data.json', 'r', encoding='utf-8') as f:\n",
        "    loaded_data = json.load(f)\n",
        "```\n",
        "\n",
        "#### **Handling API Responses**\n",
        "```python\n",
        "import requests\n",
        "\n",
        "response = requests.post(api_url, headers=headers, json=request_data)\n",
        "if response.status_code == 200:\n",
        "    result = response.json()  # Automatically parses JSON\n",
        "    content = result['choices'][0]['message']['content']\n",
        "    print(content)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccf2d809",
      "metadata": {
        "id": "ccf2d809"
      },
      "source": [
        "\n",
        "\n",
        "### Example: LLM API Response\n",
        "\n",
        "A typical LLM API response in JSON:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6275b044",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6275b044",
        "outputId": "1eb5d92c-c39b-4325-c674-51b5b31fa868"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'choices': [{'message': {'role': 'assistant',\n",
              "    'content': 'The main subject of this post is violence and identity.'}}],\n",
              " 'usage': {'prompt_tokens': 50, 'completion_tokens': 20}}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "{\n",
        "  \"choices\": [\n",
        "    {\n",
        "      \"message\": {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"The main subject of this post is violence and identity.\"\n",
        "      }\n",
        "    }\n",
        "  ],\n",
        "  \"usage\": {\n",
        "    \"prompt_tokens\": 50,\n",
        "    \"completion_tokens\": 20\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "88e3821a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88e3821a",
        "outputId": "a8747a90-9cf6-4fcd-efc9-3383d8ba85ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POLITICAL ANALYSIS WITH OPENROUTER API\n",
            "============================================================\n",
            "‚úÖ API key loaded successfully\n",
            "üîÑ Sending request to OpenRouter API...\n",
            "üìù Model: openai/gpt-3.5-turbo\n",
            "üìä Max tokens: 1000\n",
            "üå°Ô∏è Temperature: 0.1\n",
            "--------------------------------------------------\n",
            "‚úÖ Analysis completed successfully!\n",
            "============================================================\n",
            "üìñ POST ANALYSIS RESULTS\n",
            "============================================================\n",
            "1. Main themes:\n",
            "The main themes in this text excerpt are patriotism, pride in the United States, and excitement about the relocation of the U.S. Space Command headquarters to Huntsville, Alabama. The text also emphasizes the significance of this move by renaming Huntsville as \"ROCKET CITY.\"\n",
            "\n",
            "2. Emotional tone and sentiment:\n",
            "The emotional tone of the text is highly positive and enthusiastic. The use of words like \"thrilled,\" \"beautiful locale,\" and \"WE LOVE ALABAMA!\" conveys a sense of excitement and pride. The writer's sentiment is one of celebration and admiration for the decision to relocate the Space Command headquarters to Huntsville.\n",
            "\n",
            "3. References to violence:\n",
            "There are no explicit references to violence in this text. The mention of the U.S. Space Command headquarters and Huntsville being renamed as \"ROCKET CITY\" alludes to themes of power, technology, and advancement rather than violence.\n",
            "\n",
            "4. Rhetorical devices used:\n",
            "- Alliteration: The repetition of the \"R\" sound in \"ROCKET CITY\" creates a catchy and memorable phrase.\n",
            "- Exclamation marks: The use of exclamation marks throughout the text adds emphasis and conveys the writer's excitement.\n",
            "- Emotive language: Words like \"thrilled,\" \"beautiful,\" and \"LOVE\" evoke strong emotions and contribute to the overall positive tone of the text.\n",
            "\n",
            "5. Historical or social context suggested:\n",
            "The text reflects a sense of American exceptionalism and pride in technological achievements, particularly in the field of space exploration. The choice of Huntsville, Alabama as the new headquarters for the U.S. Space Command may be a nod to the city's historical significance in the development of space technology, as it is home to NASA's Marshall Space Flight Center. The renaming of Huntsville as \"ROCKET CITY\" also suggests a desire to further solidify its reputation as a hub for space-related activities. Overall, the text aligns with a broader narrative of American innovation and progress in the realm of space exploration.\n",
            "============================================================\n",
            "\n",
            "üìä API Usage Statistics:\n",
            "   ‚Ä¢ Prompt tokens: 171\n",
            "   ‚Ä¢ Completion tokens: 403\n",
            "   ‚Ä¢ Total tokens: 574\n",
            "\n",
            "üíæ Analysis completed at: 2025-09-05T14:36:39.444440\n",
            "You can now save this analysis to a file or database for your research.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import requests\n",
        "from datetime import datetime\n",
        "\n",
        "def analyze_extremist_text_with_openrouter():\n",
        "    \"\"\"\n",
        "    Demonstrate OpenRouter API usage for political extremism analysis\n",
        "    \"\"\"\n",
        "\n",
        "    # # Step 1: Get API key from environment - we already loaded this globally earlier\n",
        "    # api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "\n",
        "    if not open_router_api_key:\n",
        "        print(\"‚ùå Error: OPENROUTER_API_KEY environment variable not found\")\n",
        "        print(\"\\nTo set up your API key:\")\n",
        "        print(\"1. Get an API key from https://openrouter.ai/\")\n",
        "        print(\"2. Set environment variable: OPENROUTER_API_KEY_LNB=your_key_here\")\n",
        "        return None\n",
        "\n",
        "    print(\"‚úÖ API key loaded successfully\")\n",
        "\n",
        "    # Step 2: Set up the API endpoint and headers\n",
        "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {open_router_api_key}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"HTTP-Referer\": \"https://www.henryhenryhenry.com\",  # Your project URL\n",
        "        \"X-Title\": \"UNM 2025 LLM Workshop - Extremist Rhetoric Analysis\"\n",
        "    }\n",
        "\n",
        "    # Step 3: Sample text for analysis\n",
        "    post_text = \"\"\"\n",
        "    I am thrilled to report that the U.S. Space Command headquarters will\n",
        "    move to the beautiful locale of a place called Huntsville, Alabama ‚Äî f\n",
        "    orever to be known, from this point forward, as ROCKET CITY. WE LOVE ALABAMA!\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 4: Create the request payload\n",
        "    request_data = {\n",
        "        \"model\": \"openai/gpt-3.5-turbo\",  # Using GPT-3.5 for cost-effectiveness\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"You are a political scientist specializing in extremism\n",
        "                and political violence. Analyze texts for extremism, emotional content,\n",
        "                references to violence, rhetorical devices. Provide detailed, scholarly analysis.\"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"Please analyze this Latvian text excerpt for the following elements:\n",
        "\n",
        "1. Main themes\n",
        "2. Emotional tone and sentiment\n",
        "3. References to violence\n",
        "4. Rhetorical devices used\n",
        "5. Historical or social context suggested\n",
        "\n",
        "Text to analyze:\n",
        "{post_text}\n",
        "\n",
        "Please provide your analysis in English, with specific references to the text.\"\"\"\n",
        "            }\n",
        "        ],\n",
        "        \"max_tokens\": 1000,\n",
        "        \"temperature\": 0.1,  # Low temperature for consistent, analytical responses\n",
        "        \"top_p\": 0.9\n",
        "    }\n",
        "\n",
        "    # Step 5: Make the API request\n",
        "    try:\n",
        "        print(\"üîÑ Sending request to OpenRouter API...\")\n",
        "        print(f\"üìù Model: {request_data['model']}\")\n",
        "        print(f\"üìä Max tokens: {request_data['max_tokens']}\")\n",
        "        print(f\"üå°Ô∏è Temperature: {request_data['temperature']}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        response = requests.post(url, headers=headers, json=request_data, timeout=30)\n",
        "\n",
        "        # Check if request was successful\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Step 6: Parse the JSON response\n",
        "        result = response.json()\n",
        "\n",
        "        # Step 7: Extract and display the analysis\n",
        "        if 'choices' in result and len(result['choices']) > 0:\n",
        "            analysis = result['choices'][0]['message']['content']\n",
        "\n",
        "            print(\"‚úÖ Analysis completed successfully!\")\n",
        "            print(\"=\" * 60)\n",
        "            print(\"üìñ POST ANALYSIS RESULTS\")\n",
        "            print(\"=\" * 60)\n",
        "            print(analysis)\n",
        "            print(\"=\" * 60)\n",
        "\n",
        "            # Display usage statistics\n",
        "            if 'usage' in result:\n",
        "                usage = result['usage']\n",
        "                print(f\"\\nüìä API Usage Statistics:\")\n",
        "                print(f\"   ‚Ä¢ Prompt tokens: {usage.get('prompt_tokens', 'N/A')}\")\n",
        "                print(f\"   ‚Ä¢ Completion tokens: {usage.get('completion_tokens', 'N/A')}\")\n",
        "                print(f\"   ‚Ä¢ Total tokens: {usage.get('total_tokens', 'N/A')}\")\n",
        "\n",
        "            # Return the full response for further processing\n",
        "            return {\n",
        "                'text_analyzed': post_text,\n",
        "                'analysis': analysis,\n",
        "                'model_used': request_data['model'],\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'usage_stats': result.get('usage', {}),\n",
        "                'full_response': result\n",
        "            }\n",
        "\n",
        "        else:\n",
        "            print(\"‚ùå Error: No analysis returned from the API\")\n",
        "            return None\n",
        "\n",
        "    except requests.exceptions.Timeout:\n",
        "        print(\"‚ùå Error: Request timed out. Please try again.\")\n",
        "        return None\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        print(f\"‚ùå HTTP Error: {e}\")\n",
        "        if response.status_code == 401:\n",
        "            print(\"   This usually means your API key is invalid or expired.\")\n",
        "        elif response.status_code == 429:\n",
        "            print(\"   Rate limit exceeded. Please wait before making another request.\")\n",
        "        return None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"‚ùå Request Error: {e}\")\n",
        "        return None\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"‚ùå Error: Invalid JSON response from API\")\n",
        "        return None\n",
        "\n",
        "# Run the analysis\n",
        "print(\"POLITICAL ANALYSIS WITH OPENROUTER API\")\n",
        "print(\"=\" * 60)\n",
        "result = analyze_extremist_text_with_openrouter()\n",
        "\n",
        "if result:\n",
        "    print(f\"\\nüíæ Analysis completed at: {result['timestamp']}\")\n",
        "    print(\"You can now save this analysis to a file or database for your research.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f20ba0ed",
      "metadata": {
        "id": "f20ba0ed"
      },
      "source": [
        "### Understanding the Code Structure\n",
        "\n",
        "#### **1. Environment Variable Setup**\n",
        "```python\n",
        "open_router_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "```\n",
        "- **Secure access**: API key stored in environment variable\n",
        "- **Error handling**: Graceful failure if key not found\n",
        "- **Best practice**: Never hardcode sensitive credentials\n",
        "\n",
        "#### **2. Request Headers**\n",
        "```python\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {open_router_api_key}\",\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"HTTP-Referer\": \"https://bssdh.eu/\",\n",
        "    \"X-Title\": \"BSSDH 2025 LLM Workshop - Latvian Literature Analysis\"\n",
        "}\n",
        "```\n",
        "- **Authorization**: Bearer token authentication\n",
        "- **Content-Type**: Tells API we're sending JSON data\n",
        "- **HTTP-Referer**: Identifies your project (optional but recommended)\n",
        "- **X-Title**: Descriptive title for usage tracking\n",
        "\n",
        "#### **3. JSON Request Structure**\n",
        "```python\n",
        "request_data = {\n",
        "    \"model\": \"openai/gpt-3.5-turbo\",\n",
        "    \"messages\": [\n",
        "        {\"role\": \"system\", \"content\": \"System instructions...\"},\n",
        "        {\"role\": \"user\", \"content\": \"User query...\"}\n",
        "    ],\n",
        "    \"max_tokens\": 1000,\n",
        "    \"temperature\": 0.1\n",
        "}\n",
        "```\n",
        "- **model**: Specifies which LLM to use\n",
        "- **messages**: Conversation format with system and user roles\n",
        "- **max_tokens**: Limits response length (controls cost)\n",
        "- **temperature**: Controls creativity (0 = deterministic, 1 = creative)\n",
        "\n",
        "#### **4. Error Handling**\n",
        "The code includes comprehensive error handling for:\n",
        "- **Authentication errors** (401): Invalid API key\n",
        "- **Rate limiting** (429): Too many requests\n",
        "- **Network timeouts**: Connection issues\n",
        "- **JSON parsing errors**: Malformed responses\n",
        "\n",
        "### Popular Models for Digital Humanities\n",
        "\n",
        "#### **For Analysis Tasks**\n",
        "```python\n",
        "# Cost-effective for bulk analysis\n",
        "\"openai/gpt-3.5-turbo\"\n",
        "\n",
        "# More sophisticated analysis\n",
        "\"openai/gpt-4-turbo\"\n",
        "\n",
        "# Large context for long documents\n",
        "\"anthropic/claude-3-sonnet\"\n",
        "\n",
        "# Fast and economical\n",
        "\"google/gemini-flash-2.5\"\n",
        "```\n",
        "\n",
        "#### **For Multilingual Tasks**\n",
        "```python\n",
        "# Strong multilingual capabilities\n",
        "\"openai/gpt-4\"\n",
        "\n",
        "# Good for European languages\n",
        "\"anthropic/claude-3-opus\"\n",
        "\n",
        "# Open source alternative\n",
        "\"meta-llama/llama-3-70b-instruct\"\n",
        "```\n",
        "\n",
        "### Customizing for Your Research\n",
        "\n",
        "#### **System Prompts for Different Tasks**\n",
        "```python\n",
        "# For sentiment analysis\n",
        "system_prompt = \"\"\"You are an expert in sentiment analysis of historical texts.\n",
        "Analyze the emotional content and provide numerical scores for different emotions.\"\"\"\n",
        "\n",
        "# For named entity recognition\n",
        "system_prompt = \"\"\"You are a specialist in extracting names, places, and dates\n",
        "from historical documents. Focus on accurate identification and categorization.\"\"\"\n",
        "\n",
        "# For thematic analysis\n",
        "system_prompt = \"\"\"You are a literary scholar specializing in thematic analysis.\n",
        "Identify recurring themes, motifs, and symbolic elements in the text.\"\"\"\n",
        "```\n",
        "\n",
        "#### **Adjusting Parameters for Different Goals**\n",
        "```python\n",
        "# For creative interpretation (higher temperature)\n",
        "request_data[\"temperature\"] = 0.7\n",
        "\n",
        "# For factual analysis (lower temperature)\n",
        "request_data[\"temperature\"] = 0.1\n",
        "\n",
        "# For longer analysis (more tokens)\n",
        "request_data[\"max_tokens\"] = 2000\n",
        "\n",
        "# For concise summaries (fewer tokens)\n",
        "request_data[\"max_tokens\"] = 300\n",
        "```\n",
        "\n",
        "### Saving and Managing Results\n",
        "\n",
        "#### **Save Analysis to File**\n",
        "```python\n",
        "def save_analysis_to_file(result, filename):\n",
        "    \"\"\"Save analysis results to JSON file\"\"\"\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(result, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"‚úÖ Analysis saved to {filename}\")\n",
        "\n",
        "\n",
        "\n",
        "### Troubleshooting Common Issues\n",
        "\n",
        "#### **Authentication Problems**\n",
        "- Verify API key is correct and active - if it is your private key you can print it and check with issued key\n",
        "- Check environment variable name matches exactly\n",
        "- Ensure no extra spaces in the API key\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "836ecfb2",
      "metadata": {
        "id": "836ecfb2"
      },
      "source": [
        "### Creating generic function for OpenRouter API requests\n",
        "\n",
        "Now that we made a function with specific system prompt, user query and specific model, let's create a more generic function that can be used for any OpenRouter API request. This function will allow you to specify the system prompt, user query, model, and other parameters dynamically.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a9f75c23",
      "metadata": {
        "id": "a9f75c23",
        "outputId": "b503fb9a-0d14-4c70-cf79-e314fae68078",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response from OpenRouter API:\n",
            "Well, that depends on whether you enjoy watching the same politicians on C-SPAN for decades or if you prefer a revolving door of new faces and ideas. It's like deciding between rewatching your favorite movie a hundred times or taking a chance on a new blockbuster - variety is the spice of life, right?\n"
          ]
        }
      ],
      "source": [
        "# let's define a generic function for OpenRouter API requests\n",
        "# it should have tshould define a new function get_openrouter_response it should have following parameters system_prompt, user_prompt,\n",
        "#  model defaulting to ChatGPT 3.5 and finally api_key which defaults to open_router_api_key .\n",
        "#  The function get_openrouter_response should function just like analyze_latvian_text_with_openrouter except with parameters.\n",
        "\n",
        "def get_openrouter_response(system_prompt, user_prompt, model=\"openai/gpt-3.5-turbo\", api_key=open_router_api_key):\n",
        "    \"\"\"\n",
        "    Generic function to make requests to OpenRouter API with specified parameters.\n",
        "\n",
        "    :param system_prompt: The system prompt to guide the model's behavior.\n",
        "    :param user_prompt: The user query or text to analyze.\n",
        "    :param model: The model to use for the request (default is GPT-3.5).\n",
        "    :param api_key: The OpenRouter API key (default is loaded from environment).\n",
        "    :return: The response from the OpenRouter API.\n",
        "    \"\"\"\n",
        "\n",
        "    # Set up the API endpoint and headers\n",
        "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {api_key}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"HTTP-Referer\": \"https://www.digitalhumanities.lv/bssdh/2025/\",  # Your project URL\n",
        "        \"X-Title\": \"BSSDH 2025 LLM Workshop - Generic OpenRouter Request\"\n",
        "    }\n",
        "\n",
        "    # Create the request payload\n",
        "    request_data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        \"max_tokens\": 1000,\n",
        "        \"temperature\": 0.5,\n",
        "        \"top_p\": 0.9\n",
        "    }\n",
        "\n",
        "    # Make the API request\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, json=request_data, timeout=30)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        result = response.json()\n",
        "\n",
        "        if 'choices' in result and len(result['choices']) > 0:\n",
        "            return result['choices'][0]['message']['content']\n",
        "\n",
        "        else:\n",
        "            print(\"‚ùå Error: No response returned from the API\")\n",
        "            return None\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"‚ùå Request Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# let's test it on simple Meaning of Life question\n",
        "\n",
        "system_prompt = \"You are a helpful research assistant that provides concise answers to political science questions. Your answers should be humourous.\"\n",
        "user_prompt = \"Are Congressional term limits a good idea?\"\n",
        "\n",
        "response = get_openrouter_response(system_prompt, user_prompt) # note we did not pass model or api_key, so it will use defaults of \"openai/gpt-3.5-turbo\" and open_router_api_key\n",
        "\n",
        "if response:\n",
        "    print(\"Response from OpenRouter API:\")\n",
        "    print(response)\n",
        "else:\n",
        "    print(\"Failed to get a response from OpenRouter API.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79b78144",
      "metadata": {
        "id": "79b78144"
      },
      "source": [
        "## Class Exercise - Create your own LLM API request\n",
        "\n",
        "You have all been shown an API key for the OpenRouter API. Your task is to create a new query that analyzes a document of your choice using the OpenRouter API.\n",
        "\n",
        "For this exercise supply your document as string variable to get_openrouter_response function, and specify the system prompt and user query that you want to use for the analysis.\n",
        "\n",
        "For those with more experience try changing model or even adjust temperature or max_tokens parameters to see how it affects the response. Note changing temperature and max_tokens will require rewriting or adjusting the get_openrouter_response function to accept these parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7db3c65c",
      "metadata": {
        "id": "7db3c65c",
        "outputId": "9f19f76f-6860-4677-abfe-4201f40e19be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response from OpenRouter API:\n",
            "The original author of the text is Charles Dickens, from the novel \"A Tale of Two Cities.\" \n",
            "The modification made to the text is changing \"best\" to \"blurst.\" \n",
            "The modification was made by the user.\n"
          ]
        }
      ],
      "source": [
        "# Adjust both system and content prompts for a class exercise to your liking!\n",
        "my_system_prompt = \"Identify the original author and also the modifications made to the text and who made them.\"\n",
        "my_content_prompt = \"It was the best of times, it was the blurst of times\"\n",
        "# calling the function with these prompts\n",
        "response = get_openrouter_response(my_system_prompt, my_content_prompt)\n",
        "# how many responses we got\n",
        "if response:\n",
        "    print(\"Response from OpenRouter API:\")\n",
        "    print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28228aee",
      "metadata": {
        "id": "28228aee"
      },
      "source": [
        "## Best Practices for API usage\n",
        "\n",
        "#### **1. Documentation**\n",
        "- **Log all API calls**: Keep records of what models and parameters you used\n",
        "- **Version control**: Track changes to your analysis methods\n",
        "- **Reproducible scripts**: Write code that others can run and verify\n",
        "\n",
        "#### **2. Error Handling**\n",
        "```python\n",
        "import requests\n",
        "\n",
        "try:\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "    response.raise_for_status()  # Raises an exception for bad status codes\n",
        "    result = response.json()\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"API request failed: {e}\")\n",
        "```\n",
        "\n",
        "#### **3. Rate Limiting and Costs**\n",
        "- **Respect rate limits**: Don't overwhelm the service\n",
        "- **Monitor usage**: Track your API costs\n",
        "- **Batch efficiently**: Group similar requests when possible\n",
        "\n",
        "#### **4. Data Privacy**\n",
        "- **Sensitive data**: Be cautious with personal or confidential historical materials\n",
        "- **Institutional policies**: Check your institution's data use guidelines\n",
        "- **Terms of service**: Understand how API providers handle your data\n",
        "\n",
        "### Popular APIs for Digital Humanities\n",
        "\n",
        "#### **LLM APIs**\n",
        "- **OpenRouter**: Access to multiple models through one interface - what we use in this workshop\n",
        "- **OpenAI API**: Direct access to GPT models\n",
        "- **Anthropic API**: Claude models with large context windows\n",
        "- **Hugging Face API**: Open-source models\n",
        "\n",
        "### Security Considerations\n",
        "\n",
        "#### **API Key Management**\n",
        "- **Never commit keys to version control**\n",
        "- **Use environment variables** to store sensitive information\n",
        "- **Rotate keys regularly**\n",
        "- **Limit key permissions** where possible set budgets and access levels\n",
        "\n",
        "#### **Example: Secure Key Storage**\n",
        "```python\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Safely access your API key\n",
        "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"API key not found in environment variables\")\n",
        "```\n",
        "\n",
        "### Testing and Development\n",
        "\n",
        "#### **Start Small**\n",
        "1. **Test with short texts** before processing large corpora\n",
        "2. **Use cheaper models** for initial experiments\n",
        "3. **Validate outputs** with known examples\n",
        "4. **Compare multiple models** for the same task\n",
        "\n",
        "#### **API Testing Tools**\n",
        "- **Postman**: Visual interface for testing API calls\n",
        "- **curl**: Command-line tool for simple tests\n",
        "- **Python requests library**: For programmatic testing\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d6419ed",
      "metadata": {
        "id": "5d6419ed"
      },
      "source": [
        "## Securely loading API keys in your environment\n",
        "\n",
        "When working with APIs, especially those that require authentication, it's essential to handle API keys securely. Exposing your API keys can lead to unauthorized access and potential misuse of your account. Here are some best practices for securely loading API keys in your environment:\n",
        "\n",
        "### 1. Use Environment Variables\n",
        "Store your API keys in system environment variables instead of hardcoding them in your scripts. This keeps sensitive information out of your codebase and version control.\n",
        "```python\n",
        "import os\n",
        "# Load API key from environment variable\n",
        "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"API key not found in environment variables\")\n",
        "```\n",
        "\n",
        "Above would require that you set up the environment variable `OPENROUTER_API_KEY` in your operating system or development environment.\n",
        "\n",
        "Since most of us in this workshop are using Google Colab we do not have this particular system variable set up. Instead, we will use a `.env` file to store our API key and load it using the `python-dotenv` library.\n",
        "\n",
        "### 2. Use a `.env` File\n",
        "For local development, you can use a `.env` file to store your environment variables. This file should not be committed to version control (add it to your `.gitignore` file).\n",
        "```plaintext\n",
        "# .env file\n",
        "OPENROUTER_API_KEY=your_api_key_here\n",
        "```\n",
        "\n",
        "### 3. Use a Library to Load Environment Variables\n",
        "Use a library like `python-dotenv` to load environment variables from a `.env` file.\n",
        "```python\n",
        "from dotenv import load_dotenv\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "# Now you can access your API key\n",
        "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"API key not found in environment variables\")\n",
        "```\n",
        "\n",
        "### 4. Keep Your `.env` File Secure\n",
        "Ensure that your `.env` file is not accessible to unauthorized users. Set appropriate file permissions and avoid sharing it publicly.\n",
        "\n",
        "### 5. Rotate Your API Keys Regularly\n",
        "Regularly rotate your API keys to minimize the risk of unauthorized access. Most API providers allow you to generate new keys and revoke old ones.\n",
        "\n",
        "### 6. Set limits on API Key Usage\n",
        "If your API provider allows it, set usage limits on your API keys to prevent abuse. This can include rate limiting or restricting access to specific IP addresses or applications. In our workshop each individual API KEY has a limit of 1 Euro, which is sufficient for the workshop tasks.\n",
        "\n",
        "### 7. Alternative use getpass\n",
        "If you prefer not to use a `.env` file, you can use the `getpass` module to securely prompt for your API key at runtime. This way, the key is not stored in your code or a file.\n",
        "```python\n",
        "import getpass\n",
        "# Prompt for API key securely without showing it on the screen\n",
        "api_key = getpass.getpass(\"Enter your OpenRouter API key: \")\n",
        "if not api_key:\n",
        "    raise ValueError(\"API key cannot be empty\")\n",
        "```\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}