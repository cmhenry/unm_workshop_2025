{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bluesky API Tutorial for Political Science Research üó≥Ô∏èüìä\n",
        "\n",
        "## Introduction to Social Media Data Collection Using Bluesky's AT Protocol\n",
        "\n",
        "**Target Audience:** Political Science Graduate Students  \n",
        "**Prerequisites:** Basic familiarity with spreadsheets; no Python experience required  \n",
        "**Platform:** Google Colab (runs in your web browser)  \n",
        "**Duration:** 60-90 minutes\n",
        "\n",
        "---\n",
        "\n",
        "## What You'll Learn üéØ\n",
        "\n",
        "By the end of this tutorial, you'll be able to:\n",
        "1. **Collect social media data** from Bluesky for political research\n",
        "2. **Analyze user networks** and political discourse patterns\n",
        "3. **Export data** for use in statistical software (R, SPSS, Stata)\n",
        "4. **Visualize political conversations** and community structures\n",
        "5. **Understand ethical considerations** in social media research\n",
        "\n",
        "---\n",
        "\n",
        "## Part 1: Getting Started with Google Colab\n",
        "\n",
        "### Step 1: Setting Up Your Environment\n",
        "\n",
        "```python\n",
        "# First, let's install the required libraries\n",
        "# The exclamation mark (!) tells Colab to run this as a system command\n",
        "!pip install atproto pandas matplotlib seaborn networkx wordcloud\n",
        "\n",
        "# Import the libraries we'll use\n",
        "import pandas as pd  # For data analysis (like Excel but more powerful)\n",
        "import matplotlib.pyplot as plt  # For creating charts\n",
        "import seaborn as sns  # For prettier charts\n",
        "import networkx as nx  # For network analysis\n",
        "from wordcloud import WordCloud  # For word clouds\n",
        "import json  # For handling data\n",
        "from datetime import datetime, timedelta\n",
        "import time  # For adding delays between API calls\n",
        "\n",
        "# Configure display settings\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ All libraries installed successfully!\")\n",
        "print(\"üìã Ready to begin data collection from Bluesky\")\n",
        "```\n",
        "\n",
        "### Step 2: Understanding Bluesky and the AT Protocol\n",
        "\n",
        "**What is Bluesky?**\n",
        "- Bluesky is a decentralized social media platform\n",
        "- Built on the AT Protocol (Authenticated Transfer Protocol)\n",
        "- Users have unique identifiers called DIDs (Decentralized Identifiers)\n",
        "- All public data is accessible for research purposes\n",
        "\n",
        "**Why is this useful for political science research?**\n",
        "- Study political discourse in real-time\n",
        "- Analyze network structures of political communities\n",
        "- Track information flow during campaigns or crises\n",
        "- Examine public opinion formation\n",
        "\n",
        "---\n",
        "\n",
        "## Part 2: Authentication and Basic Setup\n",
        "\n",
        "### Step 3: Setting Up Bluesky API Access\n",
        "\n",
        "```python\n",
        "# Import the Bluesky SDK\n",
        "from atproto import Client\n",
        "\n",
        "# Initialize the client\n",
        "client = Client()\n",
        "\n",
        "# For this tutorial, we'll use public data (no authentication required)\n",
        "# If you need to access private data or post content, you would use:\n",
        "# client.login('your_handle.bsky.social', 'your_password')\n",
        "\n",
        "print(\"üîó Successfully connected to Bluesky API\")\n",
        "print(\"üìñ Ready to access public data\")\n",
        "```\n",
        "\n",
        "**Important Note for Researchers:**\n",
        "- Most political research uses public data, which doesn't require authentication\n",
        "- If you need to authenticate, create an \"App Password\" in Bluesky settings (never use your main password)\n",
        "- Always follow your institution's IRB guidelines for social media research\n",
        "\n",
        "---\n",
        "\n",
        "## Part 3: Basic Data Collection\n",
        "\n",
        "### Step 4: Understanding User Identification\n",
        "\n",
        "```python\n",
        "def resolve_handle_to_did(handle):\n",
        "    \"\"\"\n",
        "    Convert a Bluesky handle (like 'user.bsky.social') to a DID\n",
        "    DIDs are permanent identifiers, handles can change\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.com.atproto.identity.resolve_handle({'handle': handle})\n",
        "        return response.did\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Could not resolve handle {handle}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example: Let's look up some political accounts\n",
        "political_handles = [\n",
        "    'bsky.app',  # Official Bluesky account\n",
        "    'atproto.com',  # AT Protocol account\n",
        "]\n",
        "\n",
        "print(\"üîç Resolving political accounts to DIDs:\")\n",
        "political_dids = {}\n",
        "for handle in political_handles:\n",
        "    did = resolve_handle_to_did(handle)\n",
        "    if did:\n",
        "        political_dids[handle] = did\n",
        "        print(f\"‚úÖ {handle} ‚Üí {did}\")\n",
        "    else:\n",
        "        print(f\"‚ùå Failed to resolve {handle}\")\n",
        "```\n",
        "\n",
        "### Step 5: Collecting User Posts\n",
        "\n",
        "```python\n",
        "def get_user_posts(did, limit=20):\n",
        "    \"\"\"\n",
        "    Collect recent posts from a specific user\n",
        "    Returns a list of post data\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.com.atproto.repo.list_records({\n",
        "            'repo': did,\n",
        "            'collection': 'app.bsky.feed.post',\n",
        "            'limit': limit\n",
        "        })\n",
        "        \n",
        "        posts = []\n",
        "        for record in response.records:\n",
        "            post_data = {\n",
        "                'uri': record.uri,\n",
        "                'text': record.value.text,\n",
        "                'created_at': record.value.created_at,\n",
        "                'author_did': did,\n",
        "                'reply_count': getattr(record.value, 'reply_count', 0),\n",
        "                'repost_count': getattr(record.value, 'repost_count', 0),\n",
        "                'like_count': getattr(record.value, 'like_count', 0)\n",
        "            }\n",
        "            posts.append(post_data)\n",
        "        \n",
        "        return posts\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error collecting posts: {e}\")\n",
        "        return []\n",
        "\n",
        "# Collect posts from our political accounts\n",
        "print(\"üìù Collecting recent posts...\")\n",
        "all_posts = []\n",
        "\n",
        "for handle, did in political_dids.items():\n",
        "    print(f\"Collecting posts from {handle}...\")\n",
        "    user_posts = get_user_posts(did, limit=10)\n",
        "    all_posts.extend(user_posts)\n",
        "    time.sleep(1)  # Be respectful to the API\n",
        "\n",
        "print(f\"‚úÖ Collected {len(all_posts)} posts total\")\n",
        "```\n",
        "\n",
        "### Step 6: Converting to DataFrame for Analysis\n",
        "\n",
        "```python\n",
        "# Convert our posts to a pandas DataFrame (like an Excel spreadsheet)\n",
        "posts_df = pd.DataFrame(all_posts)\n",
        "\n",
        "if not posts_df.empty:\n",
        "    # Convert timestamp to readable date\n",
        "    posts_df['created_at'] = pd.to_datetime(posts_df['created_at'])\n",
        "    posts_df['date'] = posts_df['created_at'].dt.date\n",
        "    \n",
        "    # Add text length column\n",
        "    posts_df['text_length'] = posts_df['text'].str.len()\n",
        "    \n",
        "    print(\"üìä Data Summary:\")\n",
        "    print(f\"Number of posts: {len(posts_df)}\")\n",
        "    print(f\"Date range: {posts_df['date'].min()} to {posts_df['date'].max()}\")\n",
        "    print(f\"Average post length: {posts_df['text_length'].mean():.1f} characters\")\n",
        "    \n",
        "    # Display first few posts\n",
        "    print(\"\\nüìñ Sample posts:\")\n",
        "    display(posts_df[['text', 'created_at', 'like_count']].head())\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No posts collected. Try different accounts or check your connection.\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Part 4: Data Analysis for Political Research\n",
        "\n",
        "### Step 7: Temporal Analysis of Political Activity\n",
        "\n",
        "```python\n",
        "# Analyze posting patterns over time\n",
        "if not posts_df.empty:\n",
        "    # Group posts by date\n",
        "    daily_posts = posts_df.groupby('date').size().reset_index(name='post_count')\n",
        "    \n",
        "    # Create visualization\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(daily_posts['date'], daily_posts['post_count'], marker='o')\n",
        "    plt.title('Daily Posting Activity', fontsize=16, fontweight='bold')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Number of Posts')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"üìà Temporal Analysis Complete\")\n",
        "    print(\"üí° Research Applications:\")\n",
        "    print(\"   ‚Ä¢ Track political engagement during events\")\n",
        "    print(\"   ‚Ä¢ Identify patterns in campaign communication\")\n",
        "    print(\"   ‚Ä¢ Analyze response to political crises\")\n",
        "```\n",
        "\n",
        "### Step 8: Content Analysis with Word Clouds\n",
        "\n",
        "```python\n",
        "# Create word cloud from post content\n",
        "if not posts_df.empty:\n",
        "    # Combine all post text\n",
        "    all_text = ' '.join(posts_df['text'].astype(str))\n",
        "    \n",
        "    # Remove common words that aren't meaningful for political analysis\n",
        "    from wordcloud import STOPWORDS\n",
        "    political_stopwords = STOPWORDS.union({\n",
        "        'https', 'http', 'com', 'www', 'co', 'amp', 'rt', 'via'\n",
        "    })\n",
        "    \n",
        "    # Generate word cloud\n",
        "    wordcloud = WordCloud(\n",
        "        width=800,\n",
        "        height=400,\n",
        "        background_color='white',\n",
        "        stopwords=political_stopwords,\n",
        "        max_words=100,\n",
        "        colormap='viridis'\n",
        "    ).generate(all_text)\n",
        "    \n",
        "    # Display\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title('Most Common Terms in Political Posts', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"‚òÅÔ∏è Word Cloud Analysis Complete\")\n",
        "    print(\"üí° Research Applications:\")\n",
        "    print(\"   ‚Ä¢ Identify key political themes\")\n",
        "    print(\"   ‚Ä¢ Track issue salience over time\")\n",
        "    print(\"   ‚Ä¢ Compare discourse across different actors\")\n",
        "```\n",
        "\n",
        "### Step 9: Engagement Analysis\n",
        "\n",
        "```python\n",
        "# Analyze engagement patterns\n",
        "if not posts_df.empty:\n",
        "    # Calculate engagement metrics\n",
        "    posts_df['total_engagement'] = (\n",
        "        posts_df['like_count'] +\n",
        "        posts_df['repost_count'] +\n",
        "        posts_df['reply_count']\n",
        "    )\n",
        "    \n",
        "    # Create engagement visualization\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    # Engagement by post length\n",
        "    ax1.scatter(posts_df['text_length'], posts_df['total_engagement'], alpha=0.6)\n",
        "    ax1.set_xlabel('Post Length (characters)')\n",
        "    ax1.set_ylabel('Total Engagement')\n",
        "    ax1.set_title('Engagement vs. Post Length')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Engagement over time\n",
        "    daily_engagement = posts_df.groupby('date')['total_engagement'].mean()\n",
        "    ax2.plot(daily_engagement.index, daily_engagement.values, marker='o')\n",
        "    ax2.set_xlabel('Date')\n",
        "    ax2.set_ylabel('Average Engagement')\n",
        "    ax2.set_title('Engagement Trends Over Time')\n",
        "    ax2.tick_params(axis='x', rotation=45)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Distribution of engagement types\n",
        "    engagement_types = ['like_count', 'repost_count', 'reply_count']\n",
        "    engagement_means = [posts_df[col].mean() for col in engagement_types]\n",
        "    ax3.bar(engagement_types, engagement_means, color=['#ff7f0e', '#2ca02c', '#d62728'])\n",
        "    ax3.set_ylabel('Average Count')\n",
        "    ax3.set_title('Types of Engagement')\n",
        "    ax3.set_xticklabels(['Likes', 'Reposts', 'Replies'], rotation=45)\n",
        "    \n",
        "    # Engagement distribution\n",
        "    ax4.hist(posts_df['total_engagement'], bins=20, alpha=0.7, color='skyblue')\n",
        "    ax4.set_xlabel('Total Engagement')\n",
        "    ax4.set_ylabel('Number of Posts')\n",
        "    ax4.set_title('Distribution of Post Engagement')\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"üìä Engagement Analysis Complete\")\n",
        "    print(f\"üìã Summary Statistics:\")\n",
        "    print(f\"   ‚Ä¢ Average likes per post: {posts_df['like_count'].mean():.1f}\")\n",
        "    print(f\"   ‚Ä¢ Average reposts per post: {posts_df['repost_count'].mean():.1f}\")\n",
        "    print(f\"   ‚Ä¢ Average replies per post: {posts_df['reply_count'].mean():.1f}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Part 5: Network Analysis for Political Research\n",
        "\n",
        "### Step 10: Building Follow Networks\n",
        "\n",
        "```python\n",
        "def get_user_follows(did, limit=50):\n",
        "    \"\"\"\n",
        "    Get the accounts that a user follows\n",
        "    Useful for understanding political networks\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.com.atproto.repo.list_records({\n",
        "            'repo': did,\n",
        "            'collection': 'app.bsky.graph.follow',\n",
        "            'limit': limit\n",
        "        })\n",
        "        \n",
        "        follows = []\n",
        "        for record in response.records:\n",
        "            follows.append({\n",
        "                'follower_did': did,\n",
        "                'following_did': record.value.subject,\n",
        "                'created_at': record.value.created_at\n",
        "            })\n",
        "        \n",
        "        return follows\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error getting follows: {e}\")\n",
        "        return []\n",
        "\n",
        "# Build a small network\n",
        "print(\"üï∏Ô∏è Building political follow network...\")\n",
        "network_edges = []\n",
        "\n",
        "for handle, did in list(political_dids.items())[:2]:  # Limit to first 2 accounts\n",
        "    print(f\"Getting follows for {handle}...\")\n",
        "    follows = get_user_follows(did, limit=10)\n",
        "    network_edges.extend(follows)\n",
        "    time.sleep(1)\n",
        "\n",
        "print(f\"‚úÖ Collected {len(network_edges)} network connections\")\n",
        "```\n",
        "\n",
        "### Step 11: Visualizing Political Networks\n",
        "\n",
        "```python\n",
        "if network_edges:\n",
        "    # Create network graph\n",
        "    G = nx.DiGraph()  # Directed graph (follows are directional)\n",
        "    \n",
        "    # Add edges (connections)\n",
        "    for edge in network_edges:\n",
        "        G.add_edge(edge['follower_did'][:10], edge['following_did'][:10])\n",
        "    \n",
        "    # Create visualization\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    pos = nx.spring_layout(G, k=1, iterations=50)\n",
        "    \n",
        "    # Draw network\n",
        "    nx.draw_networkx_nodes(G, pos, node_color='lightblue',\n",
        "                          node_size=500, alpha=0.7)\n",
        "    nx.draw_networkx_edges(G, pos, edge_color='gray',\n",
        "                          arrows=True, arrowsize=20, alpha=0.5)\n",
        "    nx.draw_networkx_labels(G, pos, font_size=8)\n",
        "    \n",
        "    plt.title('Political Follow Network on Bluesky', fontsize=16, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Network statistics\n",
        "    print(\"üîç Network Analysis:\")\n",
        "    print(f\"   ‚Ä¢ Number of nodes (accounts): {G.number_of_nodes()}\")\n",
        "    print(f\"   ‚Ä¢ Number of edges (connections): {G.number_of_edges()}\")\n",
        "    print(f\"   ‚Ä¢ Network density: {nx.density(G):.3f}\")\n",
        "    \n",
        "    print(\"\\nüí° Research Applications:\")\n",
        "    print(\"   ‚Ä¢ Map political communities and coalitions\")\n",
        "    print(\"   ‚Ä¢ Identify influential political actors\")\n",
        "    print(\"   ‚Ä¢ Track information flow patterns\")\n",
        "    print(\"   ‚Ä¢ Study political polarization\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No network data available. Try with different accounts.\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Part 6: Data Export for Further Analysis\n",
        "\n",
        "### Step 12: Preparing Data for Statistical Software\n",
        "\n",
        "```python\n",
        "# Export data for use in R, SPSS, Stata, etc.\n",
        "if not posts_df.empty:\n",
        "    # Clean and prepare data\n",
        "    export_df = posts_df.copy()\n",
        "    \n",
        "    # Create additional variables useful for political analysis\n",
        "    export_df['hour_posted'] = export_df['created_at'].dt.hour\n",
        "    export_df['day_of_week'] = export_df['created_at'].dt.day_name()\n",
        "    export_df['is_weekend'] = export_df['created_at'].dt.weekday >= 5\n",
        "    export_df['engagement_rate'] = (\n",
        "        export_df['total_engagement'] / export_df['text_length']\n",
        "    ).fillna(0)\n",
        "    \n",
        "    # Add political content indicators (basic keyword matching)\n",
        "    political_keywords = [\n",
        "        'election', 'vote', 'campaign', 'politics', 'government',\n",
        "        'policy', 'democracy', 'candidate', 'ballot', 'congress'\n",
        "    ]\n",
        "    \n",
        "    export_df['contains_political_terms'] = export_df['text'].str.lower().str.contains(\n",
        "        '|'.join(political_keywords), na=False\n",
        "    )\n",
        "    \n",
        "    export_df['political_term_count'] = export_df['text'].str.lower().str.count(\n",
        "        '|'.join(political_keywords)\n",
        "    )\n",
        "    \n",
        "    # Save to CSV\n",
        "    export_df.to_csv('bluesky_political_data.csv', index=False)\n",
        "    \n",
        "    print(\"üíæ Data Export Complete!\")\n",
        "    print(\"üìä Variables created for analysis:\")\n",
        "    print(\"   ‚Ä¢ Temporal variables: hour_posted, day_of_week, is_weekend\")\n",
        "    print(\"   ‚Ä¢ Engagement metrics: total_engagement, engagement_rate\")\n",
        "    print(\"   ‚Ä¢ Content analysis: contains_political_terms, political_term_count\")\n",
        "    print(\"   ‚Ä¢ Basic metrics: text_length, like_count, repost_count, reply_count\")\n",
        "    print(\"\\nüìÅ Data saved as: bluesky_political_data.csv\")\n",
        "    print(\"üîÑ Ready for import into R, SPSS, Stata, or other statistical software\")\n",
        "    \n",
        "    # Display summary statistics\n",
        "    print(\"\\nüìà Summary Statistics for Export:\")\n",
        "    display(export_df.describe())\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No data to export\")\n",
        "```\n",
        "\n",
        "### Step 13: Creating a Research Codebook\n",
        "\n",
        "```python\n",
        "# Create a codebook for your data\n",
        "codebook = {\n",
        "    'Variable Name': [\n",
        "        'uri', 'text', 'created_at', 'author_did', 'reply_count',\n",
        "        'repost_count', 'like_count', 'date', 'text_length',\n",
        "        'total_engagement', 'hour_posted', 'day_of_week',\n",
        "        'is_weekend', 'engagement_rate', 'contains_political_terms',\n",
        "        'political_term_count'\n",
        "    ],\n",
        "    'Description': [\n",
        "        'Unique identifier for the post',\n",
        "        'Full text content of the post',\n",
        "        'Timestamp when post was created',\n",
        "        'Unique identifier for the author',\n",
        "        'Number of replies to the post',\n",
        "        'Number of times post was reposted',\n",
        "        'Number of likes on the post',\n",
        "        'Date of post (without time)',\n",
        "        'Length of post text in characters',\n",
        "        'Sum of all engagement (likes + reposts + replies)',\n",
        "        'Hour of day when post was made (0-23)',\n",
        "        'Day of week when post was made',\n",
        "        'Whether post was made on weekend (True/False)',\n",
        "        'Engagement per character of text',\n",
        "        'Whether post contains political keywords (True/False)',\n",
        "        'Count of political keywords in post'\n",
        "    ],\n",
        "    'Type': [\n",
        "        'Text', 'Text', 'DateTime', 'Text', 'Numeric',\n",
        "        'Numeric', 'Numeric', 'Date', 'Numeric',\n",
        "        'Numeric', 'Numeric', 'Categorical',\n",
        "        'Boolean', 'Numeric', 'Boolean',\n",
        "        'Numeric'\n",
        "    ]\n",
        "}\n",
        "\n",
        "codebook_df = pd.DataFrame(codebook)\n",
        "codebook_df.to_csv('bluesky_data_codebook.csv', index=False)\n",
        "\n",
        "print(\"üìö Research Codebook Created!\")\n",
        "print(\"üìÅ Saved as: bluesky_data_codebook.csv\")\n",
        "print(\"\\nüìã Variable Documentation:\")\n",
        "display(codebook_df)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Part 7: Research Ethics and Best Practices\n",
        "\n",
        "### Important Considerations for Political Science Research üîç\n",
        "\n",
        "```python\n",
        "# Display ethical guidelines\n",
        "ethics_guidelines = \"\"\"\n",
        "üîí RESEARCH ETHICS CHECKLIST FOR SOCIAL MEDIA DATA\n",
        "\n",
        "‚úÖ IRB Approval\n",
        "   ‚Ä¢ Check if your research requires IRB approval\n",
        "   ‚Ä¢ Many institutions require approval for social media research\n",
        "   ‚Ä¢ Public data may still require ethical review\n",
        "\n",
        "‚úÖ Data Privacy\n",
        "   ‚Ä¢ Use only publicly available data\n",
        "   ‚Ä¢ Remove or anonymize personal identifiers when possible\n",
        "   ‚Ä¢ Be careful with sensitive political information\n",
        "\n",
        "‚úÖ API Compliance\n",
        "   ‚Ä¢ Respect rate limits (don't make too many requests)\n",
        "   ‚Ä¢ Follow Bluesky's Terms of Service\n",
        "   ‚Ä¢ Use app passwords, not main account passwords\n",
        "\n",
        "‚úÖ Research Transparency\n",
        "   ‚Ä¢ Document your data collection methods\n",
        "   ‚Ä¢ Report any limitations or biases in your data\n",
        "   ‚Ä¢ Make your code available for replication\n",
        "\n",
        "‚úÖ Data Storage\n",
        "   ‚Ä¢ Store data securely on approved university systems\n",
        "   ‚Ä¢ Don't keep data longer than necessary for research\n",
        "   ‚Ä¢ Follow your institution's data retention policies\n",
        "\n",
        "‚öñÔ∏è LEGAL CONSIDERATIONS\n",
        "   ‚Ä¢ Public posts are generally okay to analyze\n",
        "   ‚Ä¢ Be aware of changing platform policies\n",
        "   ‚Ä¢ Consider international data protection laws (GDPR, etc.)\n",
        "\"\"\"\n",
        "\n",
        "print(ethics_guidelines)\n",
        "```\n",
        "\n",
        "### Step 14: Creating a Methods Section Template\n",
        "\n",
        "```python\n",
        "methods_template = \"\"\"\n",
        "üìù METHODS SECTION TEMPLATE FOR YOUR RESEARCH PAPER\n",
        "\n",
        "Data Collection:\n",
        "Social media data was collected from Bluesky using the AT Protocol API.\n",
        "Data collection occurred between [START_DATE] and [END_DATE].\n",
        "We collected [N] posts from [N] political accounts identified through [SAMPLING_METHOD].\n",
        "\n",
        "Sample:\n",
        "Our sample included [DESCRIPTION OF ACCOUNTS/USERS].\n",
        "Accounts were selected based on [SELECTION_CRITERIA].\n",
        "[LIMITATIONS OF SAMPLE].\n",
        "\n",
        "Variables:\n",
        "We analyzed several dimensions of political communication:\n",
        "‚Ä¢ Temporal patterns: posting time, day of week\n",
        "‚Ä¢ Engagement: likes, reposts, replies\n",
        "‚Ä¢ Content: text length, political keywords\n",
        "‚Ä¢ Network: follow relationships between accounts\n",
        "\n",
        "Analysis:\n",
        "Data analysis was conducted using Python with the pandas library for data manipulation\n",
        "and [STATISTICAL_SOFTWARE] for inferential statistics.\n",
        "[SPECIFIC ANALYTICAL TECHNIQUES USED].\n",
        "\n",
        "Limitations:\n",
        "‚Ä¢ Data represents only Bluesky users (selection bias)\n",
        "‚Ä¢ Public posts only (may miss private political discussion)\n",
        "‚Ä¢ Limited to English-language content\n",
        "‚Ä¢ [OTHER STUDY-SPECIFIC LIMITATIONS]\n",
        "\"\"\"\n",
        "\n",
        "print(\"üìÑ Methods Section Template:\")\n",
        "print(methods_template)\n",
        "\n",
        "# Save template to file\n",
        "with open('methods_template.txt', 'w') as f:\n",
        "    f.write(methods_template)\n",
        "\n",
        "print(\"\\nüíæ Template saved as: methods_template.txt\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Part 8: Advanced Research Applications\n",
        "\n",
        "### Step 15: Longitudinal Analysis Framework\n",
        "\n",
        "```python\n",
        "def setup_longitudinal_study():\n",
        "    \"\"\"\n",
        "    Framework for collecting data over time\n",
        "    Useful for studying political campaigns, crises, etc.\n",
        "    \"\"\"\n",
        "    framework = \"\"\"\n",
        "    üóìÔ∏è LONGITUDINAL STUDY FRAMEWORK\n",
        "    \n",
        "    Pre-Event Phase (Baseline):\n",
        "    ‚Ä¢ Collect data 2-4 weeks before key political event\n",
        "    ‚Ä¢ Establish normal patterns of discourse\n",
        "    ‚Ä¢ Identify key actors and themes\n",
        "    \n",
        "    Event Phase:\n",
        "    ‚Ä¢ Increase data collection frequency during event\n",
        "    ‚Ä¢ Monitor real-time reactions and discussions\n",
        "    ‚Ä¢ Track information spread and engagement spikes\n",
        "    \n",
        "    Post-Event Phase:\n",
        "    ‚Ä¢ Continue collection for 2-4 weeks after event\n",
        "    ‚Ä¢ Analyze sustained vs. temporary changes\n",
        "    ‚Ä¢ Document new network formations\n",
        "    \n",
        "    Research Questions for Longitudinal Analysis:\n",
        "    ‚Ä¢ How does political discourse change during crises?\n",
        "    ‚Ä¢ What information spreads fastest in political networks?\n",
        "    ‚Ä¢ How do political communities form and dissolve?\n",
        "    ‚Ä¢ What factors predict viral political content?\n",
        "    \"\"\"\n",
        "    return framework\n",
        "\n",
        "print(setup_longitudinal_study())\n",
        "```\n",
        "\n",
        "### Step 16: Comparative Analysis Setup\n",
        "\n",
        "```python\n",
        "def comparative_analysis_guide():\n",
        "    \"\"\"\n",
        "    Guide for comparing different political actors or time periods\n",
        "    \"\"\"\n",
        "    guide = \"\"\"\n",
        "    üîç COMPARATIVE ANALYSIS FRAMEWORK\n",
        "    \n",
        "    Cross-Actor Comparison:\n",
        "    ‚Ä¢ Compare politicians vs. journalists vs. activists\n",
        "    ‚Ä¢ Analyze different political parties or ideologies\n",
        "    ‚Ä¢ Study institutional vs. individual accounts\n",
        "    \n",
        "    Cross-Platform Comparison:\n",
        "    ‚Ä¢ Compare Bluesky discourse to Twitter/X\n",
        "    ‚Ä¢ Analyze migration patterns between platforms\n",
        "    ‚Ä¢ Study platform-specific political behaviors\n",
        "    \n",
        "    Cross-Time Comparison:\n",
        "    ‚Ä¢ Compare pre/post election periods\n",
        "    ‚Ä¢ Analyze seasonal patterns in political engagement\n",
        "    ‚Ä¢ Study long-term discourse evolution\n",
        "    \n",
        "    Key Metrics for Comparison:\n",
        "    ‚Ä¢ Engagement rates and patterns\n",
        "    ‚Ä¢ Network centrality and influence\n",
        "    ‚Ä¢ Content themes and sentiment\n",
        "    ‚Ä¢ Information sharing behaviors\n",
        "    \"\"\"\n",
        "    return guide\n",
        "\n",
        "print(comparative_analysis_guide())\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Part 9: Troubleshooting and Next Steps\n",
        "\n",
        "### Common Issues and Solutions üõ†Ô∏è\n",
        "\n",
        "```python\n",
        "troubleshooting_guide = \"\"\"\n",
        "‚ùì COMMON ISSUES AND SOLUTIONS\n",
        "\n",
        "Issue: \"No posts collected\"\n",
        "Solutions:\n",
        "‚Ä¢ Check if accounts are active and public\n",
        "‚Ä¢ Verify account handles are correct\n",
        "‚Ä¢ Try different political accounts\n",
        "‚Ä¢ Check your internet connection\n",
        "\n",
        "Issue: \"Rate limit exceeded\"\n",
        "Solutions:\n",
        "‚Ä¢ Add time.sleep(1) between API calls\n",
        "‚Ä¢ Reduce the number of requests\n",
        "‚Ä¢ Spread data collection over longer periods\n",
        "\n",
        "Issue: \"Empty dataframes\"\n",
        "Solutions:\n",
        "‚Ä¢ Verify accounts have recent posts\n",
        "‚Ä¢ Check date filters aren't too restrictive\n",
        "‚Ä¢ Try accounts with more activity\n",
        "\n",
        "Issue: \"Authentication errors\"\n",
        "Solutions:\n",
        "‚Ä¢ Use app passwords, not main passwords\n",
        "‚Ä¢ Check Bluesky account settings\n",
        "‚Ä¢ Verify credentials are correct\n",
        "\n",
        "Issue: \"Missing data in analysis\"\n",
        "Solutions:\n",
        "‚Ä¢ Check for None/null values in data\n",
        "‚Ä¢ Verify data types are correct\n",
        "‚Ä¢ Use .fillna() for missing values\n",
        "\"\"\"\n",
        "\n",
        "print(troubleshooting_guide)\n",
        "```\n",
        "\n",
        "### Next Steps for Advanced Research üöÄ\n",
        "\n",
        "```python\n",
        "next_steps = \"\"\"\n",
        "üéØ NEXT STEPS FOR ADVANCED POLITICAL RESEARCH\n",
        "\n",
        "Immediate Next Steps:\n",
        "1. Expand your sample size with more political accounts\n",
        "2. Implement automated data collection for longitudinal studies\n",
        "3. Add sentiment analysis to your content analysis\n",
        "4. Create more sophisticated network visualizations\n",
        "\n",
        "Intermediate Developments:\n",
        "‚Ä¢ Learn natural language processing (NLP) for content analysis\n",
        "‚Ä¢ Implement machine learning for political topic modeling\n",
        "‚Ä¢ Develop automated political event detection\n",
        "‚Ä¢ Create real-time political monitoring dashboards\n",
        "\n",
        "Advanced Research Directions:\n",
        "‚Ä¢ Study political information cascades and viral spread\n",
        "‚Ä¢ Analyze political polarization through network analysis\n",
        "‚Ä¢ Develop predictive models for political engagement\n",
        "‚Ä¢ Create comparative studies across multiple platforms\n",
        "\n",
        "Additional Resources:\n",
        "‚Ä¢ Political Science + Data Science: \"Bit by Bit\" by Matthew Salganik\n",
        "‚Ä¢ Network Analysis: \"Networks, Crowds, and Markets\" by Easley & Kleinberg\n",
        "‚Ä¢ Text Analysis: \"Text Analysis with R\" by Silge & Robinson\n",
        "‚Ä¢ Social Media Research: \"Digital Sociology\" by Lupton\n",
        "\n",
        "üîó Useful Libraries for Future Development:\n",
        "‚Ä¢ TextBlob or VADER for sentiment analysis\n",
        "‚Ä¢ scikit-learn for machine learning\n",
        "‚Ä¢ Plotly for interactive visualizations\n",
        "‚Ä¢ Streamlit for creating web applications\n",
        "\"\"\"\n",
        "\n",
        "print(next_steps)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Part 10: Assignment Ideas for Instructors üë©‚Äçüè´\n",
        "\n",
        "```python\n",
        "assignment_ideas = \"\"\"\n",
        "üìö ASSIGNMENT IDEAS FOR POLITICAL SCIENCE COURSES\n",
        "\n",
        "Beginner Assignments (Week 1-2):\n",
        "1. Data Collection Portfolio\n",
        "   ‚Ä¢ Collect 100 posts from 5 political accounts\n",
        "   ‚Ä¢ Create basic visualizations of posting patterns\n",
        "   ‚Ä¢ Write 500-word methodology reflection\n",
        "\n",
        "2. Political Network Mapping\n",
        "   ‚Ä¢ Map follow relationships among 10 political accounts\n",
        "   ‚Ä¢ Identify central and peripheral actors\n",
        "   ‚Ä¢ Discuss implications for political influence\n",
        "\n",
        "Intermediate Assignments (Week 3-4):\n",
        "3. Campaign Communication Analysis\n",
        "   ‚Ä¢ Compare pre/post election communication patterns\n",
        "   ‚Ä¢ Analyze engagement differences across account types\n",
        "   ‚Ä¢ Create presentation of findings\n",
        "\n",
        "4. Crisis Communication Study\n",
        "   ‚Ä¢ Analyze political discourse during major news event\n",
        "   ‚Ä¢ Track information spread and reaction patterns\n",
        "   ‚Ä¢ Write research report with policy implications\n",
        "\n",
        "Advanced Projects (Semester-long):\n",
        "5. Longitudinal Political Engagement Study\n",
        "   ‚Ä¢ Track political accounts over full semester\n",
        "   ‚Ä¢ Analyze seasonal patterns and event responses\n",
        "   ‚Ä¢ Create comprehensive research paper\n",
        "\n",
        "6. Comparative Platform Analysis\n",
        "   ‚Ä¢ Compare political discourse on Bluesky vs. other platforms\n",
        "   ‚Ä¢ Develop theoretical framework for platform differences\n",
        "   ‚Ä¢ Present findings at student research conference\n",
        "\n",
        "Assessment Criteria:\n",
        "‚Ä¢ Data collection methodology (25%)\n",
        "‚Ä¢ Analysis sophistication (25%)\n",
        "‚Ä¢ Visualization quality (20%)\n",
        "‚Ä¢ Written communication (20%)\n",
        "‚Ä¢ Code documentation (10%)\n",
        "\"\"\"\n",
        "\n",
        "print(assignment_ideas)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Conclusion üéì\n",
        "\n",
        "**Congratulations!** You've completed the Bluesky API tutorial for political science research. You now have the tools to:\n",
        "\n",
        "- ‚úÖ Collect social media data using the AT Protocol\n",
        "- ‚úÖ Analyze political discourse patterns\n",
        "- ‚úÖ Visualize political networks and engagement\n",
        "- ‚úÖ Export data for statistical analysis\n",
        "- ‚úÖ Conduct ethical social media research\n",
        "\n",
        "### Key Takeaways for Political Scientists:\n",
        "\n",
        "1. **Social media data provides unprecedented insights** into political behavior and discourse\n",
        "2. **Network analysis reveals power structures** and information flow patterns\n",
        "3. **Temporal analysis helps understand** how political events shape discourse\n",
        "4. **Ethical considerations are paramount** in social media research\n",
        "5. **Replication and transparency** are essential for credible research\n",
        "\n",
        "### Final Tips:\n",
        "- Start small and build complexity gradually\n",
        "- Always document your methods thoroughly\n",
        "- Collaborate with computer science colleagues when possible\n",
        "- Stay updated on platform changes and new research methods\n",
        "- Remember that code is a tool for answering political questions, not an end in itself\n",
        "\n",
        "**Happy researching!** üó≥Ô∏èüìäüî¨\n",
        "\n",
        "---\n",
        "\n",
        "*This tutorial was created for educational purposes. Always follow your institution's IRB guidelines and respect platform terms of service when conducting research.*"
      ],
      "metadata": {
        "id": "-90GAR9FkMrC"
      }
    }
  ]
}